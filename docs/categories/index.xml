<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Categories on </title>
		<link>https://ixiaopan.github.io/blog/categories/</link>
		<description>Recent content in Categories </description>
		<generator>Hugo -- gohugo.io</generator>
		
  		<language>en</language>
		
		<managingEditor>Page(/categories) (ixiaopan)</managingEditor>
    	
  		<lastBuildDate>Thu, 03 Jun 2021 00:00:00 +0000</lastBuildDate>
		
		<atom:link href="/blog/categories/" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Constrained Optimisation</title>
			<link>https://ixiaopan.github.io/blog/post/constrained-optimisation/</link>
			<pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/constrained-optimisation/</guid>
			<description>&lt;p&gt;When I first learned machine learning, I was scared by the complicated formulas. Actually, I spent much time going over subjects like Linear Algebra and Calculus since I&amp;rsquo;d already forgotten them. But with time, I feel more and more confident in understanding them, though they sometimes still confuse me. Anyway, in my opinion, there is no need to know every detail about each equation, after all, we are not mathematicians. Instead, learning how to use these math formulas to solve real-wold problems is the key.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Probabilistic Model</title>
			<link>https://ixiaopan.github.io/blog/post/probabilistic-model/</link>
			<pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/probabilistic-model/</guid>
			<description>In the previous post Descriptive Statistics, we focused on summary statistics on a particular data set. However, in machine learning, we usually attempt to make inference, i.e. infer the unknown parameters from the given data. For unknown things, we use probability to describe its uncertainty. For inference, we use Bayes&#39; rule to invert it into a forward process.
Probability At the beginning, let&amp;rsquo;s have a quick refresh on probability. Conventionly, we use a capital letter, such as $X$ or $Y$, to represent a random variable.</description>
		</item>
      	
		<item>
			<title>Semantic Web</title>
			<link>https://ixiaopan.github.io/blog/post/semanticweb/</link>
			<pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/semanticweb/</guid>
			<description>&lt;p&gt;In semester 2, I took a module called &lt;strong&gt;Semantic Web Technologies&lt;/strong&gt;. There are some reasons why I choose this module. At first glance, the name itself sounds not appealing. Actually, it does. But it&amp;rsquo;s still on my shortlist because I&amp;rsquo;ve been working on the web for many years and I wondered what the semantic web was.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Singular Value Decomposition</title>
			<link>https://ixiaopan.github.io/blog/post/svd/</link>
			<pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/svd/</guid>
			<description>&lt;p&gt;Singular Value Decomposition(SVD) is an important concept in Linear Algebra. Any matrix can be decomposed into the multiplication of three matrices using SVD. In machine learning, SVD is typically used to reduce dimensionality. Another popular dimension reduction technique is PCA. We will cover both of them in this post.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>An E2E Project - EDA</title>
			<link>https://ixiaopan.github.io/blog/post/end2end-project-01/</link>
			<pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/end2end-project-01/</guid>
			<description>&lt;p&gt;So far, we have discussed many algorithms, such as linear regression and ensemble methods. It&amp;rsquo;s time to kick off a project from scratch to learn how a real machine learning project works.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Ensemble Methods</title>
			<link>https://ixiaopan.github.io/blog/post/ensemble-methods/</link>
			<pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/ensemble-methods/</guid>
			<description>&lt;p&gt;Ensemble means a group of people or a collection of things.Thus, ensemble methods means rather than using a single model, we will use a group of different models to gain a better prediction. In fact, ensemble methods often outperform other models in Kaggle competitions. In this post, we will talk about the most popular ensemble methods , including voting, bagging, and boosting.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Decision Tree</title>
			<link>https://ixiaopan.github.io/blog/post/decision-tree/</link>
			<pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/decision-tree/</guid>
			<description>&lt;p&gt;The way decision tree works is similar to the way we make decisions in real life. For example,when you are going to watch a movie, you might have some questions on your head, such as &amp;lsquo;Is it a fiction movie? Is it directed by David Fincher?&amp;rsquo;&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Linear Regression 02</title>
			<link>https://ixiaopan.github.io/blog/post/linear-regression-02/</link>
			<pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/linear-regression-02/</guid>
			<description>&lt;p&gt;In &lt;a href=&#34;https://ixiaopan.github.io/blog/post/linear-regression-01/&#34;&gt;the previous post&lt;/a&gt;, we talked about simple linear regression. However, we only considered one predictor. It&amp;rsquo;s quite common to have multiple predictors for real-world problems. For example, if we want to predict car prices, we should consider many factors like car sizes, manufacturers and fuel types. The simple linear regression is not suitable for this case. Therefore, we need to extend it to accommodate the multiple predictors.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Bias-Variance dilemma</title>
			<link>https://ixiaopan.github.io/blog/post/bias-variance-dilemma/</link>
			<pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/bias-variance-dilemma/</guid>
			<description>&lt;p&gt;When you learn more about machine learning, you must  hear people talking about high bias, high variance or something like that. What do they mean by &amp;lsquo;high bias&amp;rsquo; or &amp;lsquo;high variance&amp;rsquo;?&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Linear Regression 01</title>
			<link>https://ixiaopan.github.io/blog/post/linear-regression-01/</link>
			<pubDate>Wed, 14 Apr 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/linear-regression-01/</guid>
			<description>&lt;p&gt;There are two main tasks in machine learning: regression and classification. Today we will talk about regression, more specifically, linear regression. Linear regression is simple and easy to understand. Perhaps it is the first algorithm that most people learn in the world of machine learning. So let&amp;rsquo;s go!&lt;/p&gt;</description>
		</item>
      	
	</channel>
</rss>
