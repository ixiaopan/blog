<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Deep Learning on </title>
		<link>https://ixiaopan.github.io/blog/categories/deep-learning/</link>
		<description>Recent content in Deep Learning </description>
		<generator>Hugo -- gohugo.io</generator>
		
  		<language>en</language>
		
		<managingEditor>Page(/categories/deep-learning) (ixiaopan)</managingEditor>
    	
  		<lastBuildDate>Thu, 09 Sep 2021 00:00:00 +0000</lastBuildDate>
		
		<atom:link href="/blog/categories/deep-learning/" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Deep Learning - Preliminary</title>
			<link>https://ixiaopan.github.io/blog/post/dl-01-pre/</link>
			<pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/dl-01-pre/</guid>
			<description>&lt;p&gt;So far, we&amp;rsquo;ve covered most of the things that we should know about machine learning, including concepts, optimization, and popular models under the hood. Yet, some advanced techniques, such as the Gaussian Process and MCMC, are not mentioned. We will talk about them later. From now on, we will move to Deep Learning. But before that, we are going to revisit some math knowledge.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Leetcode - 102</title>
			<link>https://ixiaopan.github.io/blog/post/leetcode-02/</link>
			<pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/leetcode-02/</guid>
			<description>&lt;p&gt;Practice! Practice! Practice!&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Leetcode - 101</title>
			<link>https://ixiaopan.github.io/blog/post/leetcode-01/</link>
			<pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/leetcode-01/</guid>
			<description>&lt;p&gt;Practice! Practice! Practice!&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Daily SQL Practice</title>
			<link>https://ixiaopan.github.io/blog/post/sql/</link>
			<pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/sql/</guid>
			<description>&lt;p&gt;Practice! Practice! Practice!&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Interview - Software Engineer</title>
			<link>https://ixiaopan.github.io/blog/post/interview/</link>
			<pubDate>Thu, 29 Jul 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/interview/</guid>
			<description>&lt;p&gt;From the beginning of July, I started to look for job opportunities in Data Science, Front-End, or both. The whole process is time-consuming and tedious. Now I have achieved my goal ( I mean the experience in seeking a job, I still have no offer for now ), so I am going to share my idea and recent thoughts about job seeking.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Deep Learning - PyTorch</title>
			<link>https://ixiaopan.github.io/blog/post/dl-00-pytorch/</link>
			<pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/dl-00-pytorch/</guid>
			<description>&lt;p&gt;The most popular deep learning frameworks so far are Tensorflow and PyTorch. Well, during my study, I use PyTorch more often. Recently, I am building the classic BiLSTM-CRF model using PyTorch. It&amp;rsquo;s a bit hard for me when operating matrices since it uses various advanced techniques about indexing and slicing. I think it&amp;rsquo;s necessary to explain these amazing functions. Therefore, I am going to write this post to revisit the most important aspects of PyTorch for future references.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Sorting</title>
			<link>https://ixiaopan.github.io/blog/post/sort/</link>
			<pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/sort/</guid>
			<description>&lt;p&gt;Data structure and algorithms are two important courses in Computer Science. Knowing how to utilise appropriate data structures and algorithms to fit our problems can greatly decrease memory space and improve performance. Besides, the ideas behind the classical algorithms are also worth learning to strengthen our logical thinking skills. Well, this series of articles are simply quick notes to help refresh my knowledge for future reference. So let&amp;rsquo;s start from sorting.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>NLP - Text representation</title>
			<link>https://ixiaopan.github.io/blog/post/nlp-02-text-representation/</link>
			<pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/nlp-02-text-representation/</guid>
			<description>&lt;p&gt;In the last post, we talked about text preprocessing techniques. However, even the data is clean now, they are still text. We still haven&amp;rsquo;t answered the question: how to covert text into numbers? In NLP parlance, this is called &lt;strong&gt;text representation&lt;/strong&gt;.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>NLP - Text preprocessing</title>
			<link>https://ixiaopan.github.io/blog/post/nlp-01-text-preprocessing/</link>
			<pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/nlp-01-text-preprocessing/</guid>
			<description>&lt;p&gt;From now on, we will focus on a specific domain â€” Natural Language Processing(NLP), in part because my summer project is about Named Entities Recognition(NER). Therefore, I need to know some text preprocessing techniques and have a good understanding of the state-of-art NLP models, particularly BiLSTM + CRF. The very first step in NLP is text preprocessing, so I am going to start from here.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Naive Bayes Classification</title>
			<link>https://ixiaopan.github.io/blog/post/naive-bayes/</link>
			<pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/naive-bayes/</guid>
			<description>&lt;p&gt;In the previous articles, we introduced several classification algorithms like logistic regression. These models are often called discriminative models since they make prediction by calculating $P(Y|X)$ directly. Sometimes it might be hard to compute. Another way to think of this is that samples are generated from the existed distributions. And one of the most popular models is Naive Bayes classification.&lt;/p&gt;</description>
		</item>
      	
	</channel>
</rss>
