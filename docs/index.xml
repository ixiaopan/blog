<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title></title>
		<link>https://ixiaopan.github.io/blog/</link>
		<description>Recent content </description>
		<generator>Hugo -- gohugo.io</generator>
		
  		<language>en</language>
		
		<managingEditor>Page(&#34;&#34;) (ixiaopan)</managingEditor>
    	
  		<lastBuildDate>Sun, 11 Jul 2021 00:00:00 +0000</lastBuildDate>
		
		<atom:link href="/blog/" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Sorting</title>
			<link>https://ixiaopan.github.io/blog/post/sort/</link>
			<pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/sort/</guid>
			<description>&lt;p&gt;Data structure and algorithm are two important courses in Computer Science. Knowing how to utilise appropriate data structures and algorithms to fit our problems can greatly decrease memory space and improve performance. Besides, the ideas behind the classical algorithms are also worth learning to strengthen our logical thinking skills. Today, I will introduce four common sorting algorithms. Well, I am not going to repeat things we&amp;rsquo;ve known, so this is simply a quick note to help refresh my knowledge for future reference.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>NLP - Word representation</title>
			<link>https://ixiaopan.github.io/blog/post/nlp-02-word-vector/</link>
			<pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/nlp-02-word-vector/</guid>
			<description>&lt;p&gt;In the last post, we talked about some text preprocessing techniques. However, even the data is clean now, they are still text. We still haven&amp;rsquo;t answered the question: how to covert text into numbers? There are two aspects to consider: the definition of the term &amp;ldquo;word&amp;rdquo; and where the numbers come from.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Deep Learning - Introduction</title>
			<link>https://ixiaopan.github.io/blog/post/dl-01-intro/</link>
			<pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/dl-01-intro/</guid>
			<description>&lt;p&gt;So far, we&amp;rsquo;ve covered most of the things that we should know about machine learning, including concepts, optimization, and popular models under the hood. Yet, some advanced techniques, such as the Gaussian Process and MCMC, are not mentioned. I am afraid that I don&amp;rsquo;t have time to do this because I have to do my summer project, which requires me to dive into deep learning.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>NLP - Text preprocessing</title>
			<link>https://ixiaopan.github.io/blog/post/nlp-01-text-preprocessing/</link>
			<pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/nlp-01-text-preprocessing/</guid>
			<description>&lt;p&gt;From now on, we will focus on a specific domain — Natural Language Processing(NLP), in part because my summer project is about Named Entities Recognition(NER). Therefore, I need to know some text preprocessing techniques and have a good understanding of the state-of-art NLP models, particularly BiLSTM + CRF. The very first step in NLP is text preprocessing, so I am going to start from here.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Naive Bayes Classification</title>
			<link>https://ixiaopan.github.io/blog/post/naive-bayes/</link>
			<pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/naive-bayes/</guid>
			<description>&lt;p&gt;In the previous articles, we introduced several classification algorithms like logistic regression. These models are often called discriminative models since they make prediction by calculating $P(Y|X)$ directly. Sometimes it might be hard to compute. Another way to think of this is that samples are generated from the existed distributions. And one of the most popular models is Naive Bayes classification.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Support Vector Machine</title>
			<link>https://ixiaopan.github.io/blog/post/svm/</link>
			<pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/svm/</guid>
			<description>Maximise the margin Given a linearly separable set of data $D = (x_i, y_i)_{i=1}^n$ where $y_i \in -1, 1$, there are many lines that separates the data. Which one is the best? Intuitively, the line with the largest distance to all samples generates more space to avoid misclassification. Mathematically, this can be described as follows,
$$ y_i d_i \ge \Delta $$
where $d_i$ is the distance from $x_i$ to the separating plane and $\Delta$ is the margin.</description>
		</item>
      	
		<item>
			<title>K-means</title>
			<link>https://ixiaopan.github.io/blog/post/kmeans/</link>
			<pubDate>Mon, 14 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/kmeans/</guid>
			<description>&lt;p&gt;So far, we&amp;rsquo;ve talked much about supervised learning. Aside from it, there exist many other learning types such as unspervised learning, semi-supervised learning and so on. This post will introduce one of the most widely used unsupervised clustering algorithms — K-means. We will cover the implementation of K-means algorithm, the limitation of this algorithm as well as its applications.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Logistic Regression</title>
			<link>https://ixiaopan.github.io/blog/post/logistic-regression/</link>
			<pubDate>Mon, 14 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/logistic-regression/</guid>
			<description>&lt;p&gt;We&amp;rsquo;ve known that linear regression can be used to predict a continuous value, but sometimes the target variable might be categorical, i.e. whether tomorrow is sunny or someone has a cancer. Can we still use linear regression to solve this classification problem? The answer is Yes and the algorithm that we will introduce in this article is known as logistic regression. Well, we can also try Perceptron since it&amp;rsquo;s also a linear classifier. PS: Don&amp;rsquo;t mix it up with linear regression. Logistic regression is a classification algorithm.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>Perceptron</title>
			<link>https://ixiaopan.github.io/blog/post/perceptron/</link>
			<pubDate>Sun, 13 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/perceptron/</guid>
			<description>&lt;p&gt;Perceptron is a traditional classification algorithm and it is the basis of the neural network. Though it&amp;rsquo;s out of date, it plays a historical role in the development of neural network. Knowing how it works will help us lay the foundations for the future study of the neural network.&lt;/p&gt;</description>
		</item>
      	
		<item>
			<title>K-nearest neighbours</title>
			<link>https://ixiaopan.github.io/blog/post/knn/</link>
			<pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate>
			<guid>https://ixiaopan.github.io/blog/post/knn/</guid>
			<description>&lt;p&gt;K-Nearest Neighbors(KNN) is a distance-based algorithm in machine learning used for both classification and regression. It&amp;rsquo;s simple and intutive to understand because it doesn&amp;rsquo;t require extra training step and the idea behind it is simple enough — similar points are tends to be close to each other. In this article, we will learn how KNN works.&lt;/p&gt;</description>
		</item>
      	
	</channel>
</rss>
