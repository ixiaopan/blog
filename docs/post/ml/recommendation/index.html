<!DOCTYPE html>
<html
  lang="en"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          Recommender Systems - xiaopan&#39;s blog
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="xiaopan" />
  <meta name="description" content="Recommender system is one of the most popular studying fields in machine learning due to its wide application in our daily life. When you shop online, such as Amazon, you can see similar items just below the item you are looking at. The goal of a recommender system is to make recommendations that fit the user&amp;rsquo;s taste. In this post, we will go through the very basic concepts and several classcial techniques in the field of recommender systems." />







<meta name="generator" content="Hugo 0.81.0" />


<link rel="canonical" href="https://ixiaopan.github.io/blog/post/ml/recommendation/" />





<link rel="icon" href="/blog/favicon.ico" />











<link rel="stylesheet" href="/blog/sass/jane.min.74977c7446e205bad48a3e6fbb98e0a1566bd939e7c40ca1aecde689a0a1376e.css" integrity="sha256-dJd8dEbiBbrUij5vu5jgoVZr2TnnxAyhrs3miaChN24=" media="screen" crossorigin="anonymous">







<meta property="og:title" content="Recommender Systems" />
<meta property="og:description" content="Recommender system is one of the most popular studying fields in machine learning due to its wide application in our daily life. When you shop online, such as Amazon, you can see similar items just below the item you are looking at. The goal of a recommender system is to make recommendations that fit the user&rsquo;s taste. In this post, we will go through the very basic concepts and several classcial techniques in the field of recommender systems." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ixiaopan.github.io/blog/post/ml/recommendation/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-11-07T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2021-11-07T00:00:00&#43;00:00" />

<meta itemprop="name" content="Recommender Systems">
<meta itemprop="description" content="Recommender system is one of the most popular studying fields in machine learning due to its wide application in our daily life. When you shop online, such as Amazon, you can see similar items just below the item you are looking at. The goal of a recommender system is to make recommendations that fit the user&rsquo;s taste. In this post, we will go through the very basic concepts and several classcial techniques in the field of recommender systems."><meta itemprop="datePublished" content="2021-11-07T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2021-11-07T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="3121">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Recommender Systems"/>
<meta name="twitter:description" content="Recommender system is one of the most popular studying fields in machine learning due to its wide application in our daily life. When you shop online, such as Amazon, you can see similar items just below the item you are looking at. The goal of a recommender system is to make recommendations that fit the user&rsquo;s taste. In this post, we will go through the very basic concepts and several classcial techniques in the field of recommender systems."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/blog/" class="logo">Pan</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">This is Home</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">Archives</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">Tags</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">Categories</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/about/">About</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/blog/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/blog/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/blog/" class="logo">
    
      Pan
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">This is Home</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">Archives</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">Tags</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/">Categories</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://ixiaopan.github.io/blog/about/">About</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">Recommender Systems</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      <a href="/blog/about">
        <span class="post-meta-author-name">
          xiaopan
        </span>
      </a>
    
  </div>

  <div class="post-meta-time">
    <time datetime="2021-11-07">
      2021-11-07
    </time>
  </div>

  


  <div class="post-meta__right">
    

    <div class="post-meta-category">
        <a href="https://ixiaopan.github.io/blog/categories/machine-learning/"> Machine Learning </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <p>Recommender system is one of the most popular studying fields in machine learning due to its wide application in our daily life. When you shop online, such as Amazon, you can see similar items just below the item you are looking at. The goal of a recommender system is to make recommendations that fit the user&rsquo;s taste. In this post, we will go through the very basic concepts and several classcial techniques in the field of recommender systems.</p>
<h2 id="overview">Overview</h2>
<p><img src="/blog/post/images/recom.png#full" alt="" title="Figure 1: Different algorithms for recommender systems."></p>
<p>Recommendations can be classified as two categories, as Figure 1 shows,</p>
<ul>
<li>non-personalised
<ul>
<li>recommendations are the same for all users</li>
<li>e.g. the most popular movies, the top ten hotels, &hellip;</li>
</ul>
</li>
<li>personalised
<ul>
<li>recommendations vary by users</li>
</ul>
</li>
</ul>
<p>Obviously, we focus on the latter one. The mainstream algorithms includes</p>
<ul>
<li>content-based filtering
<ul>
<li>recommend items based on the attribtues of items, users, or both (feature engineering)</li>
<li>e.g. when you buy the novel &ldquo;The ABC Murders &ldquo;, the system will also recommend other novels written by Agatha Christie to you.</li>
</ul>
</li>
<li>collaborative filtering
<ul>
<li>employ the wisdom of the crowd instead of extracting good attributes manually</li>
</ul>
</li>
</ul>
<p>There are three main types of collaborative algorithms, namely,</p>
<ul>
<li>user-based filtering</li>
<li>item-based filtering</li>
<li>matrix factorisation</li>
</ul>
<h2 id="data">Data</h2>
<p>Data is all we need. Figure 2 shows that a recommender system needs three types of data,</p>
<ul>
<li>items data</li>
<li>user data</li>
<li>the interaction between items and users</li>
</ul>
<p><img src="/blog/post/images/input-recom.png#full" alt="" title="Figure 2: Data involved in recommender systems."></p>
<p>Each type of data has its own properties. Items like clothes have attributes of size and colour. Users have age and gender. The interactions between items and users include contextual attributes, such as weather, geographical location, day of the week, and so on.</p>
<h3 id="item-content-matrix-icm">Item Content Matrix (ICM)</h3>
<p>As mentioned earlier, items have attributes. Mathematically, we can describe that relation using Item Content Matrix or ICM, where each row indicates an item and each column represents an attribute. The value of ICM usually is 1 or 0. If an item contains a specific attribute listed in ICM, the corresponding cell will be set to one, zero otherwise. But you can also set a value between 0 and 1 to describe the importance of that attribute or other numerical values for quantitative variables like year.</p>
<h3 id="user-rating-matrix-urm">User Rating Matrix (URM)</h3>
<p>Similarly, the opinions of users on items are described mathematically through the User Rating Matrix or URM. Each row represents a user, and each column represents an item. If we have no idea the opinion of someone on an item, the corresponding value is missing (when computing, you can treat it as zero).</p>
<h4 id="implict-ratings">Implict Ratings</h4>
<p>Ratings can be implicit or explicit. Implicit ratings are deduced by looking at how you interact with the system, for instance, the time-on-page, the viewing time of a movie, clicks, purchases, and so on. If one stops watching a movie after 10 minutes, we assume that that user does not like that movie. However, one may have to stop watching a film because of an important call.</p>
<h4 id="explict-ratings">Explict Ratings</h4>
<p>Explicit ratings are done by asking users to rate items on a rating scale, for example, five stars for Educated.  However, designing a rating scale is not an easy thing. It depends on your application, customers, and so on. As shown in the following table, a smaller and odd rating scale is generally preferable due to its simplicity and variety. In practice, we always see a one-to-five rating or &lsquo;like/dislike&rsquo; buttons at almost every website that needs to collect users' opinions.</p>
<table>
<thead>
<tr>
<th>Large rating scale</th>
<th>Smaller rating scale</th>
<th>Even rating scale</th>
<th>Odd rating scale</th>
</tr>
</thead>
<tbody>
<tr>
<td>complex and requires more effort</td>
<td>easy to understand</td>
<td>either negative or positive ratings, forcing people to express their opinions</td>
<td>introduces the neutral rating, which makes people feel more comfortable</td>
</tr>
<tr>
<td>fewer ratings</td>
<td>more ratings</td>
<td>fewer ratings</td>
<td>people tend to choose the neutral rating unless they have a strong positive or negative opinion</td>
</tr>
</tbody>
</table>
<h2 id="non-personalised-recs">Non-personalised recs</h2>
<h3 id="top-10">Top 10</h3>
<p>As we said before, the top 10 perhaps is the most common type of non-personalised recs. You can see Top 10 everywhere on the Internet.</p>
<h4 id="method-1-top-popular">Method 1: Top Popular</h4>
<p>An intuitive method to get the top 10 items is to order items by the number of users that have bought, seen, or given their opinions.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># top 10 movies</span>
movies_has_seen <span style="color:#f92672">=</span> Log<span style="color:#f92672">.</span>objects<span style="color:#f92672">.</span>values(<span style="color:#e6db74">&#39;content_id&#39;</span>)<span style="color:#f92672">.</span>filter(event<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;seen&#39;</span>)<span style="color:#f92672">.</span>annotate(Count(<span style="color:#e6db74">&#39;user_id&#39;</span>))

sorted_items <span style="color:#f92672">=</span> sorted(movies_has_seen, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> item: <span style="color:#f92672">-</span>float(item[<span style="color:#e6db74">&#39;user_id__count&#39;</span>]))

sorted_items[:<span style="color:#ae81ff">10</span>]
</code></pre></div><h4 id="method-2-the-best-rated-items">Method 2: The Best Rated Items</h4>
<p>Another technique is to calculate the average rating for each item and retrieve the top 10 items ranked by the average rating in descending order.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">movies_avg_rated <span style="color:#f92672">=</span> Rating<span style="color:#f92672">.</span>objects<span style="color:#f92672">.</span>values(<span style="color:#e6db74">&#39;movie_id&#39;</span>)<span style="color:#f92672">.</span>annotate(Avg(<span style="color:#e6db74">&#39;rating&#39;</span>))

sorted(movies_avg_rated, key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> item: <span style="color:#f92672">-</span>float(item[<span style="color:#e6db74">&#39;rating__avg&#39;</span>]))[:<span style="color:#ae81ff">10</span>]
</code></pre></div><p>To calculate the average rating, we need the help of URM. Let $r_{ui}$ be the non-zero rating given by user $u$ to item $i$, and $N_i$ be the number of users who rated item $i$,  then the average rating of item $i$ is given as</p>
<p>$$
b_i = \frac{\sum_u r_{ui} }{N_i}
$$</p>
<h3 id="market-basket-analysis">Market Basket Analysis</h3>
<p>Apart from the &ldquo;Top 10&rdquo;, another type of recommendations also appears often when you look at an item at Amazon. That is &ldquo;Frequently Bought Together (People who bought this item also bought)&rdquo;. Basically, this kind of recommendations are based on association rule analysis (market basket analysis), which is a technique widely used by retailers to discover associations between items. They want to know what items are frequently bought together so that they can   place them in a similar manner.</p>
<p>Let $I = { I_1, I_2, &hellip;, I_m }$ be the items and $T = { t_1, t_2, .., t_N }$ a list of transactions.</p>
<h4 id="rule">Rule</h4>
<p>Association rules can be written in the form of &ldquo;IF-THEN&rdquo;,
$$
\{{ A \}} \rarr \{{ B \}}
$$
where $A \sub I$, $ B \sub I$, and $A \cap B = \empty$. The above rules means that if a customer buys $A$, then he is likely to buy $B$. A and B can include many items,
$$
\{{\text{bread},\text{milk}\}}\rarr\{{\text{carrots},\text{yogurt}\}}
$$</p>
<h4 id="support">Support</h4>
<p>Support tells us how frequently A and B appear together by calculating the fraction of transactions that contains A and B.</p>
<p>$$
\text {supp} (A \rarr B) = \frac{|A \cup B|}{|T|}
$$
Thus, we can filter out the item sets that occur less frequently by setting a minimum support.</p>
<h4 id="confidence">Confidence</h4>
<p>Confidence shows the percentage in which B is bought with A.</p>
<p>$$
\text {conf} (A \rarr B) = \frac{\text{supp}(A \rarr B)}{\text{supp}(A)}
$$</p>
<h4 id="lift">Lift</h4>
<p>Lift indicates the strength of a rule.</p>
<p>$$
\text {list} (A \rarr B) = \frac{\text{supp}(A \rarr B)}{\text{supp}(A)\text{supp}(B)}
$$</p>
<p>With these terms, now we can make an association analysis using the Apriori algorithm.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">data <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;1&#39;</span>: [<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0</span>],
    <span style="color:#e6db74">&#39;2&#39;</span>: [<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>],
    <span style="color:#e6db74">&#39;3&#39;</span>: [<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0</span>],
    <span style="color:#e6db74">&#39;4&#39;</span>: [<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">0</span>],
    <span style="color:#e6db74">&#39;5&#39;</span>: [<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>]
}
index <span style="color:#f92672">=</span> [ <span style="color:#e6db74">&#39;InvoiceNo_&#39;</span> <span style="color:#f92672">+</span> str(i) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">4</span>) ]
basket_set <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(data<span style="color:#f92672">=</span>data, index<span style="color:#f92672">=</span>index)

freq_itemsets <span style="color:#f92672">=</span> apriori(basket_set, min_support<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, use_colnames<span style="color:#f92672">=</span>True)
freq_itemsets[<span style="color:#e6db74">&#39;length&#39;</span>] <span style="color:#f92672">=</span> freq_itemsets[<span style="color:#e6db74">&#39;itemsets&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: len(x))
freq_itemsets

<span style="color:#75715e"># 0.25 (4) 1 # since 0.25 &lt; 0.5, so it&#39;s not included.</span>
support	itemsets	length
<span style="color:#ae81ff">0</span>	<span style="color:#ae81ff">0.50</span>	(<span style="color:#ae81ff">1</span>)	        <span style="color:#ae81ff">1</span>
<span style="color:#ae81ff">1</span>	<span style="color:#ae81ff">0.75</span>	(<span style="color:#ae81ff">2</span>)       	<span style="color:#ae81ff">1</span>
<span style="color:#ae81ff">2</span>	<span style="color:#ae81ff">0.75</span>	(<span style="color:#ae81ff">3</span>)       	<span style="color:#ae81ff">1</span>
<span style="color:#ae81ff">3</span>	<span style="color:#ae81ff">0.75</span>	(<span style="color:#ae81ff">5</span>)	        <span style="color:#ae81ff">1</span>
<span style="color:#ae81ff">4</span>	<span style="color:#ae81ff">0.50</span>	(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">1</span>)     	<span style="color:#ae81ff">2</span>
<span style="color:#ae81ff">5</span>	<span style="color:#ae81ff">0.50</span>	(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>)    	<span style="color:#ae81ff">2</span>
<span style="color:#ae81ff">6</span>	<span style="color:#ae81ff">0.75</span>	(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>)    	<span style="color:#ae81ff">2</span>
<span style="color:#ae81ff">7</span>	<span style="color:#ae81ff">0.50</span>	(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>)    	<span style="color:#ae81ff">2</span>
<span style="color:#ae81ff">8</span>	<span style="color:#ae81ff">0.50</span>	(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>)	<span style="color:#ae81ff">3</span>

association_rules(freq_itemsets, metric<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;confidence&#39;</span>, min_threshold<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>)

antecedents	consequents	antecedent_support	consequent_support	support confidence	lift
(<span style="color:#ae81ff">1</span>)	         (<span style="color:#ae81ff">3</span>)	       <span style="color:#ae81ff">0.50</span>	                <span style="color:#ae81ff">0.75</span>	               <span style="color:#ae81ff">0.50</span>	   <span style="color:#ae81ff">1.0</span>	<span style="color:#ae81ff">1.333333</span>
(<span style="color:#ae81ff">2</span>)	         (<span style="color:#ae81ff">5</span>)	       <span style="color:#ae81ff">0.75</span>	                <span style="color:#ae81ff">0.75</span>	               <span style="color:#ae81ff">0.75</span>	   <span style="color:#ae81ff">1.0</span>	<span style="color:#ae81ff">1.333333</span>
(<span style="color:#ae81ff">5</span>)	         (<span style="color:#ae81ff">2</span>)	       <span style="color:#ae81ff">0.75</span>	                <span style="color:#ae81ff">0.75</span>	               <span style="color:#ae81ff">0.75</span>	   <span style="color:#ae81ff">1.0</span>	<span style="color:#ae81ff">1.333333</span>
(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>)	     (<span style="color:#ae81ff">5</span>)	       <span style="color:#ae81ff">0.50</span>	                <span style="color:#ae81ff">0.75</span>	               <span style="color:#ae81ff">0.50</span>	   <span style="color:#ae81ff">1.0</span>	<span style="color:#ae81ff">1.333333</span>
(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>)	     (<span style="color:#ae81ff">2</span>)	       <span style="color:#ae81ff">0.50</span>	                <span style="color:#ae81ff">0.75</span>	               <span style="color:#ae81ff">0.50</span>	   <span style="color:#ae81ff">1.0</span>	<span style="color:#ae81ff">1.333333</span>
</code></pre></div><p>PS: <a href="https://github.com/ixiaopan/DataScience/blob/master/MachineLearning/15-MarketBasketAnalysis.ipynb">Here</a> is the complete code.</p>
<h2 id="similarity">Similarity</h2>
<p>Before introducing the personalised recs, we should be familiar with similarity. There are many ways to measure similarity or distance between two vectors, for example,</p>
<ul>
<li>Jaccard Distance</li>
<li>Mahantan Distance</li>
<li>Euclidean Distance</li>
<li>Cosine Similarity</li>
<li>Pearson Correlation Coefficient</li>
<li>K-means clustering</li>
</ul>
<h3 id="cosine-similarity">Cosine Similarity</h3>
<p>Cosine similarity between users is defined as,</p>
<p>$$
S_{uv} = \frac{r_u \cdot r_v}{||r_u|| * ||r_v||}
$$</p>
<p>where $r_u$ is the $u_{th}$ row of URM.</p>
<h3 id="adjusted-cosine-similarity">Adjusted Cosine Similarity</h3>
<p>On the other hand, we should notice is that people use different rating scales. For example, Alice is generous to rating while Bob is a bit harsh on it, so a rating of 3 in Bob is equivalent to 5 in Alice. To deal with this, we normalise the ratings by subtracting the user&rsquo;s average rating, denoted by $\overline r_u$, as follows,</p>
<p>$$
S_{uv} = \frac{(r_u - \overline r_u) \cdot (r_v - \overline r_v)}{||r_u - \overline r_u|| * ||r_v - \overline r_v||}
$$</p>
<h3 id="pearson-correlation-coefficient">Pearson Correlation Coefficient</h3>
<p>The above formula is the same as Pearson Correlation Coefficient. The only difference between them is that the Pearson only works for vectors with the same size (the rated items in common between users), while the adjusted cosine similarity considers all items by treating missing values as zero.</p>
<p>For instance, below are the ratings of Alice and Bob for six films.</p>
<pre><code>Alice: [4, 5, 4, NaN, 3, 3]
Bob:   [3, 3, 3, 2, 4, 5]
</code></pre><p>Step 1: calculating the average rating</p>
<ul>
<li>Alice: $(4+5+4+3+3)/5 = 3.8$</li>
<li>Bob: $(3+3+3+2+4+5)/6= 3.33$</li>
</ul>
<p>Step 2: Normalising ratings</p>
<ul>
<li>Adjusted Cosine</li>
</ul>
<pre><code>Alice: [0.2, 1.2, 0.2, -3.8, -0.8, -0.8]
Bob:   [-0.33, -0.33, -0.33, -1.33, 0.67, 1.67]
</code></pre><p>Notice that we treat $NaN$ as $0$.</p>
<ul>
<li>Pearson</li>
</ul>
<pre><code>Alice: [0.2, 1.2, 0.2, NaN, -0.8, -0.8]
Bob:   [-0.33, -0.33, -0.33, -1.33, 0.67, 1.67]
</code></pre><p>Step 3: Calculating similarity</p>
<ul>
<li>Adjusted Cosine</li>
</ul>
<p>$$
\frac{0.2*-0.33+1.2*-0.33+0.2*-0.33+ -3.8*-1.33 +-0.8*0.67+-0.8*1.67}{\sqrt{0.2^2+1.2^2+0.2^2+ -3.8^2+-0.8^2*2} \sqrt{-0.33^2*3+-1.33^2 + 0.67^2+1.67^2}} \\ = -0.62
$$</p>
<ul>
<li>Pearson</li>
</ul>
<p>$$
\frac{0.2*-0.33+1.2*-0.33+0.2*-0.33+-0.8*0.67+-0.8*1.67}{\sqrt{0.2^2+1.2^2+0.2^2+(-0.8)^2+(-0.8)^2}  \sqrt{-0.33^2 + -0.33^2+-0.33^2+0.67^2+1.67^2}} \\ = -0.75
$$</p>
<h3 id="overlapping">Overlapping</h3>
<p>However, the cosine similarity is not perfect enough. Figure 3 shows that the similarity between the users who rated one item only is greater than those who have more items in common. However, the result is not convincing because there are less common in the first pair of users. In other words, the similarity is not reliable when the support is small. The support is the number of non-zero ratings of a user.</p>
<p>3<img src="/blog/post/images/shirnk-similarity.png" alt="" title="Figure 6: Small support would lead to seemingly greater similarity."></p>
<p>So how to solve it? We add a shrink term $C$ to the denominator of the cosine to reduce the magnitude of the cosine similarity</p>
<p>$$
S_{uv} = \frac{r_u \cdot r_v}{||r_u|| * ||r_v|| + C}
$$</p>
<p>Alternatively, you can also set a threshold for the minimum support to filter out the users who have rated only one or two items. The codes below return the number of overlapping elements between users. On the contrary, if there are too many overlapping users, users are so alike that it&rsquo;s difficult to recommend special items (the recommendations are too general).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">overlap_matrix <span style="color:#f92672">=</span> URM<span style="color:#f92672">.</span>astype(bool)<span style="color:#f92672">.</span>astype(int)
overlap_matrix <span style="color:#f92672">=</span> overlap_matrix <span style="color:#960050;background-color:#1e0010">@</span> overlap_matrix<span style="color:#f92672">.</span>T
</code></pre></div><h3 id="neighborhood">Neighborhood</h3>
<p>In practice, we only consider a small set of similar users or items, which is called as the neighborhood of the target user or item.</p>
<h4 id="cluster">Cluster</h4>
<p>Clustering is one technique to divide data into several similar groups, so the neighborhood of a user is the group that he belongs to. However, clustering has some drawsbacks, e.g. sensitive to the shape of data.</p>
<h4 id="knn">KNN</h4>
<p>We have introduced KNN before. In the case of recs, for example, $K=2$ means that we only keep the most two similar items for each column.</p>
<p><img src="/blog/post/images/knn-similarity.png" alt="" title="Figure 4: Reduced similarity matrix after applying KNN (K=2)."></p>
<h4 id="threshold">Threshold</h4>
<p>Another simple way is to set a threshold for similarity. The figure below illustrates the difference between KNN and threshold.</p>
<p><img src="/blog/post/images/topn-threshold.png#full" alt="" title="[Source: Practical Recommender Systems]"></p>
<h2 id="content-based-filtering">Content-based Filtering</h2>
<p>Now we focus on personalised recs. We first look at content-based filtering, which is the first strategy applied in recommendations. As its name suggests, it relies on the metadata of the items without using any opinion of others, as Figure 5 shows.</p>
<p><img src="/blog/post/images/example-content-filter.png#full" alt="" title="Figure 5: Example of content-based recommendation pipeline. [Source: Practical Recommender Systems]"></p>
<p>The core of content-based filtering is to make recommendations based on the attributes of the content. However, not all attributes are useful and equally important. Besides, some features may not be explicitly visible to us. Thus, we need to extract knowledge from the content and select features carefully.</p>
<h3 id="similarity-1">Similarity</h3>
<p>We first find similarity between items by applying cosine similarity to ICM, as shown in Figure 6.</p>
<p><img src="/blog/post/images/icm-similarity.png" alt="" title="Figure 4: The similarity matrix calculated from ICM."></p>
<p>The cosine similarity is defined as,
$$
S_{ij} = \frac{\overrightarrow I_i \cdot \overrightarrow I_j}{||\overrightarrow I_i|| * || \overrightarrow I_j||}
$$
where $I_j$ indicates the $j_{th}$ item (row) in ICM.</p>
<h3 id="tf-idf">TF-IDF</h3>
<p>As mentioned previously, attributes are not of equal importance, so it&rsquo;s essential to know what features are more important and do feature selections to improve performance. TF-IDF is a technique used to analyse the importance of something like a word in NLP. In the case of ICM, we consider each item as a document and each column as a word. Suppose we want to know the importance of an attribute, say $a$, then TF and IDF are calculated as follows,</p>
<p>$$
TF_{a, i} = \frac{|I_{ai}|}{|I_i|} \\ IDF_{a} = - \text{log} \frac{|a \in I|}{|I|}
$$</p>
<p>where</p>
<ul>
<li>$I_{ai}$ is the number of $a$ appearing in the item $i$; often equal to 1</li>
<li>$I_i$ represents the number of attributes of item $i$</li>
<li>$|a \in I|$ is the number of items containing attribue $a$</li>
<li>$|I|$ is the total number of items</li>
</ul>
<h3 id="lda">LDA</h3>
<h3 id="pros-and-cons">Pros and Cons</h3>
<p>Pros</p>
<ul>
<li>You can always get recommendations even if it&rsquo;s your first visit</li>
<li>It recommends across popularity; that is, it does not care about the popular items now</li>
</ul>
<p>Cons</p>
<ul>
<li>The system is less likely to recommend new or surprising items</li>
<li>Limited understanding of content; it&rsquo;s likely to misunderstand what the customers like</li>
</ul>
<h2 id="collaborative-filtering">Collaborative Filtering</h2>
<h3 id="user-based">User-based</h3>
<p>User-based filtering works on the idea that we look for users with a similar taste and recommend the items they like most. So there are two questions here</p>
<ul>
<li>How to measure similarity between users? (See above)</li>
<li>What to recommend to the target user? Two common ways,
<ul>
<li>Average</li>
<li>Vote</li>
</ul>
</li>
</ul>
<p>With similarity matrix, we make a prediction for item $i$, given the user $u$</p>
<p>$$
\hat r_{ui} = \overline r_u + \frac{\sum_{v \in KNN(u)} S_{uv} (r_{vi} - \overline r_v)}{\sum_{v \in KNN(u)} S_{uv}}
$$</p>
<p>So, user-based CF calculates a weighted average rating of several nearest neighbours of user $u$ for item $i$.</p>
<h3 id="item-based">Item-based</h3>
<p>Likewise, the prediction using item-based CF is given as,</p>
<p>$$
\hat r_{ui} =  \overline r_u + \frac{\sum_{j \in KNN(i)} S_{ij} (r_{uj} - \overline r_u)}{\sum_{j \in KNN(i)} S_{ij}}
$$</p>
<p>where the adjusted $S_{ij}$ is defined as</p>
<p>$$
S_{ij} = \frac{\sum_u (r_{ui} - \overline r_u) (r_{uj} - \overline r_u)  }{ \sqrt{\sum_u(r_{ui} - \overline r_u) ^2} \sqrt{\sum_u(r_{uj} - \overline r_u) ^2}}
$$</p>
<h3 id="pros-and-cons-1">Pros and Cons</h3>
<p>Pros</p>
<ul>
<li>It does not need metadata about the content</li>
</ul>
<p>Cons</p>
<ul>
<li>
<p>cold start</p>
<ul>
<li>What items to recommend to a new user?</li>
<li>How to recommend a new item to users?</li>
</ul>
</li>
<li>
<p>sparse URM
$$
\text {sparsity} = 1 - \frac{|R|}{|U||I|}
$$</p>
</li>
<li>
<p>scaling can be challenging for growing datasets.</p>
</li>
</ul>
<h2 id="matrix-factorisation">Matrix Factorisation</h2>
<p>Unlike user-based CF and item-based CF, matrix factorisation aims to factorise URM into two matrices. Basically, this technique tries to find the latent factors underlying the interactions between users and items. Technically speaking, SVD and Funk SVD are two common methods to achieve this goal. They look alike at first sight but are different things.</p>
<h3 id="svd">SVD</h3>
<p>We&rsquo;ve known that any matrix can be decomposed into three matrices as shown below,</p>
<p>$$
A = U\Sigma V^T
$$
where</p>
<ul>
<li>$U^{m \times k}$ - User factor matrix</li>
<li>$\Sigma^{k \times k}$ - Diagnoal matrix</li>
<li>$V^{n\times k}$ - Item factor matrix</li>
</ul>
<p>As we know, $\Sigma$ contains singular values, which are sorted from the largest to the smallest. These values indicate the weight of the factor $k_i$, so we can remove some unimportant features by setting the corresponding singular value to zero. That&rsquo;s called truncated SVD. Besides, reducing the matrix also saves memory space. From Figure 7 we can see that zero sigular values will remove the right-most columns of $U$ and the bottom-most rows of $V^T$.</p>
<p><img src="/blog/post/images/truncated-svd.png#full" alt="" title="Figure 7: The illustration of truncated SVD."></p>
<p>For coders, below are PyTorch implementation of SVD.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">U, S, V <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>svd(A)

S[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>

A_hat <span style="color:#f92672">=</span> U <span style="color:#960050;background-color:#1e0010">@</span> torch<span style="color:#f92672">.</span>diag(S) <span style="color:#960050;background-color:#1e0010">@</span> V<span style="color:#f92672">.</span>T
</code></pre></div><p>However, there are some obvious problems with SVD. First, it&rsquo;s time-consuming to calculate large matrixes. Second, we have to impute the missing values first. Usually, we impute zero cells with user&rsquo;s average rating. Nevertheless, SVD is not very computationally efficient.</p>
<h3 id="funk-svd">Funk SVD</h3>
<p>The idea of Funk SVD proposed by Simon Funk is to compute the lower-rank approximation of a matrix by minimising the squared error loss. The difference wih SVD above is that Funk SVD only considers the known values, which means we discard the missing values in URM. Mathematically, the goal of Funk SVD is to minimise the following loss function,</p>
<p>$$
\text{min}_{p, q} \sum_{(u, i) \in K} \epsilon_{ui}^2 = \text{min}_{p, q} \sum_{(u, i) \in K} (r_{ui} - p_u q_i)^2
$$</p>
<p>where</p>
<ul>
<li>$p_u$ is the $u_{th}$ row of the user factor matrix $U$</li>
<li>$q_i$ is the $i_{th}$ column of the iterm factor matrix $Q$</li>
<li>$r_{ui}$ is the rating of the item $i$ given by the user $u$</li>
<li>$K$ is the set of all known ratings</li>
</ul>
<p>To find the solution, we first compute the derivative of $L$ w.r.t $p_u$ and $q_i$, respectively, and then use stochastic gradient descent to arrive at the minimum point.
$$
p_u \larr p_u + lr * \epsilon_{ui} q_i\\ q_i \larr q_i + lr * \epsilon_{ui} p_u
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sgd_factorise</span>(A: torch<span style="color:#f92672">.</span>Tensor, rank: int, num_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>, lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>) <span style="color:#f92672">-&gt;</span> Tuple[torch<span style="color:#f92672">.</span>Tensor, torch<span style="color:#f92672">.</span>Tensor]:
    m, n <span style="color:#f92672">=</span> A<span style="color:#f92672">.</span>shape

    U <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand((m, rank))
    V <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand((n, rank))

    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(num_epochs):
        <span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> range(m):
            <span style="color:#66d9ef">for</span> c <span style="color:#f92672">in</span> range(n):
                e <span style="color:#f92672">=</span> A[r, c] <span style="color:#f92672">-</span> U[r] <span style="color:#960050;background-color:#1e0010">@</span> V[c]<span style="color:#f92672">.</span>T
                U[r] <span style="color:#f92672">=</span> U[r] <span style="color:#f92672">+</span> lr <span style="color:#f92672">*</span> e <span style="color:#f92672">*</span> V[c]
                V[c] <span style="color:#f92672">=</span> V[c] <span style="color:#f92672">+</span> lr <span style="color:#f92672">*</span> e <span style="color:#f92672">*</span> U[r]

    <span style="color:#66d9ef">return</span> U, V
</code></pre></div><h3 id="regularization">Regularization</h3>
<p>Alternatively, we can add regularization to Funk SVD to avoid large parameters (overfitting).</p>
<p>$$
\text{min}_{p, q} \sum_{(u, i) \in K} \epsilon_{ui}^2  + \beta (||P||^2 + ||Q||^2)
$$
Now the updated rules are</p>
<p>$$
p_u \larr p_u + lr * (\epsilon_{ui} q_i - \beta p_u) \\ q_i \larr q_i + lr * (\epsilon_{ui} p_u - \beta q_i)
$$</p>
<h3 id="bias">Bias</h3>
<p>Finally, we need to consider the bias or intercept. As mentioned earlier, people have their own criterions from rating (user bias) and some items are naturally highly expected (item bias). So, the new predicted rating is defined as</p>
<p>$$
\hat r_{ui} = p_u q_i + \mu + b_u + b_i
$$</p>
<p>where $\mu$ is the global average raing, $b_u$ is the user bias, and $b_i$ is the item bias. Thus, the final loss function is defined as follows,</p>
<p>$$
\text{min}_{p, q} \sum_{(u, i) \in K} \epsilon_{ui}^2  + \beta (||P||^2 + ||Q||^2 + ||b_u||^2 + ||b_i||^2)
$$</p>
<p>The derivatives of $L$ w.r.t $b_u, b_i, p_u, q_i$ are</p>
<p>$$
b_u += \lambda (\epsilon_{ui} - \beta b_u) \\ b_i += \lambda (\epsilon_{ui} - \beta b_i) \\ p_u \larr p_u + lr * (\epsilon_{ui} q_i - \beta p_u) \\ q_i \larr q_i + lr * (\epsilon_{ui} p_u - \beta q_i)
$$</p>
<h2 id="cold-start">Cold Start</h2>
<h2 id="evaluation">Evaluation</h2>
<h3 id="baseline-predictors">Baseline Predictors</h3>
<h3 id="quality-indicators">Quality Indicators</h3>
<p>Relevance、 Coverage、Novelty、Diversity、Consistency、Confidence、Serendipity</p>
<h3 id="metrics">Metrics</h3>
<h3 id="online-evaluation">Online Evaluation</h3>
<h4 id="direct-user-feedback">Direct user feedback</h4>
<ul>
<li>ques should be meaningful and non&ndash;biased</li>
<li>opinion not reliable</li>
</ul>
<h4 id="ab-test">A/B test</h4>
<ul>
<li>monitoring user behavior</li>
<li>difficult to set up</li>
<li>result might be difficult to interpret</li>
</ul>
<h4 id="controlled-experiments">Controlled experiments</h4>
<h4 id="crowdsourcing">Crowdsourcing</h4>
<h3 id="offline-evaluation">Offline evaluation</h3>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.edureka.co/blog/apriori-algorithm/">Apriori Algorithm: Know How to Find Frequent Itemsets</a></li>
<li><a href="https://www.kaggle.com/xvivancos/market-basket-analysis">Market Basket Analysis</a></li>
<li><a href="https://www.coursera.org/specializations/recommender-systems">Recommender Systems Specialization</a></li>
<li><a href="https://www.freecodecamp.org/news/singular-value-decomposition-vs-matrix-factorization-in-recommender-systems-b1e99bc73599/">Singular Value Decomposition vs. Matrix Factorization in Recommender Systems</a></li>
<li><a href="http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/">Matrix Factorization: A Simple Tutorial and Implementation in Python</a></li>
<li><a href="https://robinwitte.com/wp-content/uploads/2019/10/RecommenderSystem.pdf">Recommender system: Using singular value decomposition as a matrix factorization approach</a></li>
</ul>

        </div>

        
        



        
        


        <footer class="post-footer">
          


          
          <nav class="post-nav">
            
              <a class="prev" href="/blog/post/ml/optimization/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">Optimization</span>
                <span class="prev-text nav-mobile">Prev</span>
              </a>
            
              <a class="next" href="/blog/post/misc/remove-splash/">
                <span class="next-text nav-default">REMOVING ANNOYING SPLASH ADs!!!</span>
                <span class="prev-text nav-mobile">Next</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      


      
      

  

  
  

  
  

  

  

    

  

  


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">Table of Contents</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#data">Data</a>
      <ul>
        <li><a href="#item-content-matrix-icm">Item Content Matrix (ICM)</a></li>
        <li><a href="#user-rating-matrix-urm">User Rating Matrix (URM)</a></li>
      </ul>
    </li>
    <li><a href="#non-personalised-recs">Non-personalised recs</a>
      <ul>
        <li><a href="#top-10">Top 10</a></li>
        <li><a href="#market-basket-analysis">Market Basket Analysis</a></li>
      </ul>
    </li>
    <li><a href="#similarity">Similarity</a>
      <ul>
        <li><a href="#cosine-similarity">Cosine Similarity</a></li>
        <li><a href="#adjusted-cosine-similarity">Adjusted Cosine Similarity</a></li>
        <li><a href="#pearson-correlation-coefficient">Pearson Correlation Coefficient</a></li>
        <li><a href="#overlapping">Overlapping</a></li>
        <li><a href="#neighborhood">Neighborhood</a></li>
      </ul>
    </li>
    <li><a href="#content-based-filtering">Content-based Filtering</a>
      <ul>
        <li><a href="#similarity-1">Similarity</a></li>
        <li><a href="#tf-idf">TF-IDF</a></li>
        <li><a href="#lda">LDA</a></li>
        <li><a href="#pros-and-cons">Pros and Cons</a></li>
      </ul>
    </li>
    <li><a href="#collaborative-filtering">Collaborative Filtering</a>
      <ul>
        <li><a href="#user-based">User-based</a></li>
        <li><a href="#item-based">Item-based</a></li>
        <li><a href="#pros-and-cons-1">Pros and Cons</a></li>
      </ul>
    </li>
    <li><a href="#matrix-factorisation">Matrix Factorisation</a>
      <ul>
        <li><a href="#svd">SVD</a></li>
        <li><a href="#funk-svd">Funk SVD</a></li>
        <li><a href="#regularization">Regularization</a></li>
        <li><a href="#bias">Bias</a></li>
      </ul>
    </li>
    <li><a href="#cold-start">Cold Start</a></li>
    <li><a href="#evaluation">Evaluation</a>
      <ul>
        <li><a href="#baseline-predictors">Baseline Predictors</a></li>
        <li><a href="#quality-indicators">Quality Indicators</a></li>
        <li><a href="#metrics">Metrics</a></li>
        <li><a href="#online-evaluation">Online Evaluation</a></li>
        <li><a href="#offline-evaluation">Offline evaluation</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  
  
    <a href="wxp201013@163.com" rel="me noopener" class="iconfont"
      title="email"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://www.linkedin.com/in/ixiaopan" rel="me noopener" class="iconfont"
      title="linkedin"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="33" height="33">
  <path d="M872.405333 872.618667h-151.637333v-237.610667c0-56.661333-1.152-129.578667-79.018667-129.578667-79.061333 0-91.136 61.653333-91.136 125.397334v241.792H398.976V384h145.664v66.602667h1.962667c20.352-38.4 69.845333-78.933333 143.786666-78.933334 153.642667 0 182.058667 101.12 182.058667 232.746667v268.202667zM227.712 317.141333a87.978667 87.978667 0 0 1-88.021333-88.106666 88.064 88.064 0 1 1 88.021333 88.106666z m76.032 555.477334H151.68V384h152.064v488.618667zM948.266667 0H75.562667C33.792 0 0 33.024 0 73.770667v876.458666C0 991.018667 33.792 1024 75.562667 1024h872.576C989.866667 1024 1024 991.018667 1024 950.229333V73.770667C1024 33.024 989.866667 0 948.138667 0h0.128z"></path>
</svg>

    </a>
  
    <a href="https://github.com/ixiaopan" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://space.bilibili.com/22910840" rel="me noopener" class="iconfont"
      title="bilibili"  target="_blank"
      >
      <svg
  class="icon" style="" viewBox="0 0 1024 1024" version="1.1" width="36"
  height="36" id="svg8">
  <path
      style=""
      d="M 744.60599,0.00486267 A 41.779915,41.779915 0 0 0 710.4184,18.673394 L 548.5048,255.32642 h -11.70046 a 41.779915,41.779915 0 0 0 -10.80295,-7.84928 L 235.66,97.084498 a 41.779915,41.779915 0 0 0 -20.07193,-4.960864 41.779915,41.779915 0 0 0 -18.3748,79.145436 L 359.4859,255.32642 H 128.16909 c -49.458302,0 -89.27932,39.82105 -89.27932,89.27932 v 508.65224 c 0,49.4583 39.821018,89.27934 89.27932,89.27934 h 19.48445 C 149.12802,984.5043 179.92773,1024 224.79179,1024 c 44.86407,0 75.66379,-39.4957 77.13826,-81.46268 H 719.98116 C 721.45559,984.5043 752.25533,1024 797.1194,1024 c 44.86406,0 75.6638,-39.4957 77.13824,-81.46268 h 21.57323 c 49.45831,0 89.27936,-39.82104 89.27936,-89.27934 V 344.60574 c 0,-49.45827 -39.82105,-89.27932 -89.27936,-89.27932 H 649.74567 L 779.38103,65.866924 A 41.779915,41.779915 0 0 0 744.60599,0.00486267 Z M 644.49108,418.70871 c 6.29985,0.21538 12.44451,2.01107 17.86888,5.22196 l 171.36218,98.10771 c 18.23417,10.21935 24.63334,33.34627 14.24614,51.48533 -10.38726,18.13909 -33.57344,24.32718 -51.61587,13.77296 L 624.9903,489.18895 c -15.21356,-8.41858 -22.66871,-26.1765 -18.03211,-42.93436 4.63664,-16.75784 20.15573,-28.14465 37.53289,-27.54588 z M 350.2006,432.31846 c 16.89952,0.0317 31.69582,11.33328 36.17844,27.62747 4.48262,16.2942 -2.44981,33.57765 -16.95507,42.24898 l -140.7157,86.91312 c -17.68528,11.18244 -41.09629,5.77692 -52.08912,-12.02686 -10.99282,-17.80373 -5.33855,-41.15658 12.58167,-51.95857 L 329.9002,438.2095 c 6.0643,-3.86439 13.10951,-5.90891 20.3004,-5.89104 z M 501.605,641.53985 c 3.75002,-0.15248 7.48645,0.53903 10.93349,2.0235 0.15842,0.0637 0.31618,0.12888 0.47325,0.19582 0.59328,0.27092 1.17574,0.56489 1.74609,0.88121 0.15868,0.0854 0.31643,0.17233 0.47325,0.2611 0.55694,0.32165 1.10131,0.66458 1.63185,1.02807 0.16455,0.1123 0.32777,0.2265 0.48956,0.34269 0.50382,0.36781 0.99371,0.75428 1.46868,1.15864 0.18724,0.15504 0.37218,0.31282 0.55484,0.47323 0.43271,0.38784 0.8518,0.79061 1.25653,1.20756 0.15449,0.16114 0.30679,0.32437 0.45693,0.48959 0.40798,0.44266 0.79989,0.89988 1.17494,1.37076 0.17799,0.22544 0.35205,0.45395 0.5222,0.68538 0.25932,0.34701 0.50964,0.70071 0.75064,1.06071 0.26712,0.39516 0.52286,0.79784 0.76699,1.20757 0.16907,0.29043 0.33231,0.58424 0.48957,0.88123 0.21836,0.41297 0.42513,0.83199 0.62009,1.25653 0.14836,0.32333 0.28983,0.64976 0.42429,0.97911 0.21319,0.51552 0.40915,1.03801 0.58747,1.5666 0.0677,0.19499 0.13296,0.39085 0.19582,0.58748 0.18652,0.60823 0.34984,1.22334 0.48957,1.84399 0.0397,0.16277 0.0779,0.32601 0.11423,0.48957 0.1436,0.69112 0.25788,1.38801 0.34269,2.08877 0.005,0.0381 0.0111,0.0761 0.0163,0.11424 0.0857,0.78056 0.13474,1.56471 0.14687,2.34988 0.005,0.0543 0.0111,0.10879 0.0163,0.1632 0,0 -0.008,1.12132 0,1.45234 0,0 -0.14697,17.84761 5.89102,34.12231 3.01902,8.13734 7.33278,15.10615 12.61433,19.61501 5.28157,4.50889 11.42894,7.62081 23.64572,7.62081 12.2168,0 18.36416,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.5953,-11.47767 12.6143,-19.61501 6.03799,-16.2747 5.89103,-34.12231 5.89103,-34.12231 -0.44885,-13.87045 10.45922,-25.46302 24.3311,-25.86506 13.87189,-0.40201 25.42828,10.53953 25.78348,24.41272 0,0 1.11929,25.7226 -9.00791,53.01927 -5.06359,13.64832 -13.1986,28.46036 -27.05631,40.29073 -13.85772,11.83039 -33.5454,19.63135 -56.20142,19.63135 -22.65603,0 -42.34371,-7.80096 -56.20141,-19.63135 -4.1801,-3.56856 -7.78733,-7.42433 -10.99878,-11.42303 -3.21235,4.00037 -6.81703,7.85309 -10.99876,11.42303 -13.85773,11.83039 -33.5454,19.63135 -56.20144,19.63135 -22.65601,0 -42.3437,-7.80096 -56.2014,-19.63135 -13.85775,-11.83037 -21.99272,-26.64241 -27.05632,-40.29073 -10.12725,-27.29667 -9.00789,-53.01928 -9.00789,-53.01927 0.20714,-13.83687 11.58744,-24.88848 25.42444,-24.69013 14.1263,0.19991 25.2971,12.0278 24.69011,26.14247 0,0 -0.14697,17.84761 5.89103,34.12231 3.01902,8.13734 7.31646,15.10615 12.598,19.61501 5.28155,4.50889 11.44526,7.62081 23.66203,7.62081 12.21681,0 18.36418,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.57899,-11.47767 12.598,-19.61501 5.76352,-15.53489 5.89112,-32.05691 5.89103,-33.56746 0.006,-0.37466 0.0111,-1.05336 0.0163,-1.20759 -0.0117,-0.74583 0.0105,-1.49177 0.0652,-2.23565 0.009,-0.15784 0.0204,-0.31561 0.0327,-0.47324 0.14204,-1.56859 0.43163,-3.12027 0.86487,-4.63449 0.0213,-0.0763 0.0433,-0.15244 0.0652,-0.22848 3.0335,-10.25748 12.24157,-17.46007 22.92769,-17.93417 z"
      id="rect824"/>
</svg>

    </a>


<a href="https://ixiaopan.github.io/blog/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
  
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2021 -
    2024
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        xiaopan
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/blog/lib/jquery/jquery-3.7.1.min.js"></script>
  <script type="text/javascript" src="/blog/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/blog/js/main.c1d1af3f9a0921a0b05ae7493629f72e7ca2ac9e76b08a207b14636632f3fdf7.js" integrity="sha256-wdGvP5oJIaCwWudJNin3LnyirJ52sIogexRjZjLz/fc=" crossorigin="anonymous"></script>






  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css"
    integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG"
    crossorigin="anonymous">

  
  <script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js"
    integrity="sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1"
    crossorigin="anonymous"></script>

  
  <script defer
    src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
    crossorigin="anonymous" onload="renderMathInElement(document.body);">
  </script>
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
        
      });
    });
  </script>






  
    <script type="text/javascript" src="/blog/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/blog/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  

















  </body>
</html>
