<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<title>Probabilistic Model</title>



  
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-203640627-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-203640627-1');
  </script>
  




<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link
  rel="alternate"
  type="application/rss+xml"
  href="https://ixiaopan.github.io/blog/index.xml"
  title=""
/>

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Probabilistic Model"/>
<meta name="twitter:description" content="In the previous post [Descriptive Statistics](https://ixiaopan.github.io/blog/post/descriptive-statistics/), we focused on summary statistics on a particular data set. However, in machine learning, we usually attempt to make inference, i.e. infer the unknown parameters from the given data. For unknown things, we use **probability** to describe its uncertainty. For inference, we use Bayes&#39; rule to invert it into a forward process"/>




<link rel="stylesheet" href="https://ixiaopan.github.io/blog/fontawesome/css/all.min.css" />
<link
  id="dark-mode-theme"
  rel="stylesheet"
  href="https://ixiaopan.github.io/blog/css/dark.css"
/>


<script>
  var darkTheme = document.getElementById('dark-mode-theme')
  var storedTheme = localStorage.getItem('dark-mode-storage')
  if (storedTheme === 'dark') {
    darkTheme.disabled = false
  } else if (storedTheme === 'light') {
    darkTheme.disabled = true
  }
</script>


<script src="https://ixiaopan.github.io/blog/js/main.bundle.js"></script>
<script src="https://ixiaopan.github.io/blog/js/instantpage.min.js" type="module" defer></script>


  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css" integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js" integrity="sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "$", right: "$", display: false}
        ]
    });
});
</script>

 




  <link rel="stylesheet" href="https://ixiaopan.github.io/blog/css/main.css" />


<meta name="generator" content="Hugo 0.81.0" />
  </head>
  <body>
    
  




  <header>
    <nav class="navbar">
  <div class="nav">
    
      <a href="https://ixiaopan.github.io/blog/" class="nav-logo">
        <img
          src="https://ixiaopan.github.io/blog/images/me.JPG"
          width="50"
          height="50"
          alt="Logo"
        />
      </a>
    

    <ul class="nav-links">
      
        
          <li>
            <a href="/blog/about/" id="About"
              ><em class="fas fa-user fa-lg"></em
            ></a>
          </li>
          
      
        
          <li>
            <a href="/blog/search" id="Search"
              ><em class="fas fa-search fa-lg"></em
            ></a>
          </li>
          
      
        
          <li>
            <a href="/blog/archives" id="Archives"
              ><em class="fas fa-archive fa-lg"></em
            ></a>
          </li>
          
      
    </ul>
  </div>
</nav>


    
    <div class="intro-header">
      <div class="container">
        <div class="post-heading">
          
            <h1>
              Probabilistic Model
            </h1>
          
          
            <span class="meta-post">
  <em class="fa fa-calendar-alt"></em
  >&nbsp;May 26, 2021
  
  &nbsp;&nbsp;<i class="fas fa-clock"></i>&nbsp;12 min read

  
    &nbsp;&nbsp;&nbsp;<em class="fa fa-folder-open"></em>&nbsp;
    
      <a
        href="https://ixiaopan.github.io/blog/categories/machine-learning/"
        >Machine Learning</a
      >&nbsp;
    
  
</span>

          
        </div>
      </div>
    </div>
    
  </header>

    
  <div class="container" role="main">
    <div class="inner">
      <article class="article" class="blog-post">
        
  <p>The goal of machine learning is to infer an unknown pattern from data. However, both parameters and predictions are estimated values, so how confident are we in these values? To measure uncertainty, we use probability. On the other hand, Bayes' theorem provides a framework for us to invert the problem into a forward process, where we observe data from parameters instead of making inferences from data.</p>
<h2 id="probability">Probability</h2>
<p>At the beginning, let&rsquo;s have a quick refresh on probability.</p>
<blockquote>
<p>A random variable is variable that can take on different values randomly.</p>
<p>On its own, it is a description the states that are possible; it must be coupled with a probability distribution that specifies how likely each of these states are.</p>
<p>â€” Deep Learning, p54</p>
</blockquote>
<p>In short, a random variable covers two aspects: possible value and the likelihood of taking that value. Conventionly, we use a capital letter, such as $X$ or $Y$, to represent a random variable. Suppose we have two random variables of interest, $X$ and $Y$,</p>
<ul>
<li>
<p>The joint probability of $X$ that takes the value of $x$ and $Y$ that takes the value of $y$ is written as $P(X = x, Y=y)$, which means that the probability of $x$ and $y$ happening at the same time</p>
</li>
<li>
<p>Given $Y=y$, the conditional probability of $X$ given $Y=y$ is denoted by $P(X|Y=y)$</p>
</li>
</ul>
<p>There are two major rules of probability that we should remember,</p>
<ul>
<li>the sum rule, i.e. the marginal probability of $X$ that takes the value of $x$, irrespective of the value of $Y$</li>
</ul>
<p>$$
P(X=x) = \sum_{y \in Y} P(X=x, Y=y)
$$</p>
<ul>
<li>the product rule, i.e. the joint probability of $X$ and $Y$ can be written as the product of the conditional probability and the marginal probability</li>
</ul>
<p>$$
P(X, Y) = P(Y|X) P(X) = P(X|Y)P(Y)
$$</p>
<p>From the above formula, we can deduce the following equation, which is also known as Bayes' Rule,</p>
<p>$$
P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}
$$</p>
<h2 id="bayes-inference">Bayes' Inference</h2>
<p>In machine learning, our goal is to learn a model $\Theta$ from a given data set $D$, but $\Theta$ is uncertain. One way to measure uncertainty is probability, so the question becomes how to compute the probablity of $\Theta$ given the data $D$, i.e. $P(\Theta|D)$.  But the only thing we know is the observed data, so how can we do it? The answer is the Bayes' Rule, which helps us convert this into a forward problem, where parameters are known and thus we can draw data from the distribution determined by that paramaters. The formula is defined as follows,</p>
<p>$$
P(\Theta|D) = \frac{P(D|\Theta)P(\Theta)}{P(D)}
$$</p>
<ul>
<li>$P(\Theta)$ is called the prior probability, i.e. the best guess about $\Theta$ before we see the data. You might have a good estimate on it or simply have no idea at all</li>
<li>$P(D|\Theta)$ is the likelihood of the data given the parameters $\Theta$</li>
<li>$P(D)$ is the evidence or marginal probability denoted by $P(D) = \sum_{\theta \in \Theta }P(D, \theta)$</li>
<li>$P(\Theta|D)$ is the posterior probability, i.e. the updated probability of $\theta_i$ after we see the data</li>
</ul>
<h3 id="pros-and-cons">Pros and cons</h3>
<p>Pros</p>
<ul>
<li>Bayes' rule provides us a full probabilistic description of the parameters</li>
<li>It doesn&rsquo;t overfit since we are not choosing the best parameters that fit the data perfectly</li>
</ul>
<p>Cons</p>
<ul>
<li>However, we need to compute $P(D)$, whichsometimes  is not reasonable, e.g. there are too many possible values of $\Theta$</li>
<li>Posterior might not be described as a nice probability function</li>
</ul>
<h3 id="map">MAP</h3>
<p>If we ignore the evidence $P(D)$ (after all, it&rsquo;s just a constant for any $\theta$), we are only left with the numerator. An easy way to compute $P(\Theta|D$) is to find the maximum value shown below, though it&rsquo;s not a strictly probability</p>
<p>$$
{\argmax}_{\Theta} log (P(D|\Theta)) + log (P(\Theta))
$$</p>
<p>This method is called <strong>Maximum A Posterior(MAP)</strong>. However, it can overfit because we are finding the parameters that maximise the likelihood of the observed data. Thus, we are likely to get a model that fit the data with no errors.</p>
<h3 id="mle">MLE</h3>
<p>Furthermore, if we ignore the prior $P(\Theta)$, the MAP is just <strong>maximising the likelihood(MLE)</strong>, which is widely used statistics in machine learning.</p>
<h2 id="conjugate-prior">Conjugate Prior</h2>
<p>In some cases, the likelihood of the observed data $D$ is simple to compute, and the posterior would have the same form as the prior if we could find a right prior. Such a likelihood and prior distribution are said to be &lsquo;conjugate&rsquo;. Here we consider two common distributions that a prior might follow: Bernoulli and Poisson.</p>
<h3 id="bernoulli-distribution">Bernoulli Distribution</h3>
<p>Suppose we have a binary random variable $X \in \{0, 1 \}$, and $X_i=1$ if the ith trial is a head and 0 otherwise. Then the likelihood of $X_i$ given the probability of a head $\mu$ is</p>
<p>$$
P(X_i = 1|\mu) = \mu
$$</p>
<p>$$
P(X_i = 0|\mu) = 1 - \mu
$$</p>
<p>Or we can write it in this form</p>
<p>$$
P(X_i|\mu) = \mu^{X_i} (1-\mu)^{1-X_i}
$$</p>
<p>Suppose we have a data set $ D = \{ x_1, x_2, &hellip;, x_n \}$, where $x_i \in \{0, 1 \}$, assuming these observations are drawn independently, then the likelihood of $D$ can be computed as follows,</p>
<p>$$
L(D;\mu) = \prod_{i=1}^N P(X_i|\mu) =  \prod_{i=1}^N \mu^{X_i} (1-\mu)^{1-X_i} = \mu^{N_h} (1-\mu)^{N-N_h}
$$
where $N_h = \sum_i X_i$, i.e number of heads.</p>
<h4 id="beta">Beta</h4>
<p>The next step is to choose the prior $P(\Theta)$. In the case of Bernoulli, it would be better if we can find a function that has a simliar exponential parts that appeared in the above likelihood function to model the probability of every single value of $\mu$. Luckily, Beta distribution shown below is the right function we are looking for.</p>
<p>$$
P(\mu) = Beta(\mu|a, b) = \frac{\mu^{a-1} (1-\mu)^{b-1}}{B(a, b)}
$$</p>
<p>where $B(a, b)$ is a normalisation constant</p>
<p>$$
B(a, b) = \int_0^1 \mu^{a-1} (1-\mu)^{b-1} d\mu
$$</p>
<p>So how to choose a, b? It depends. If we have no idea about $\mu$, it&rsquo;s natural to assume that there are equal chances to take all vaules of $\mu$. This corresponds to a beta distribution with $a = b = 1$.</p>
<p>The last step is to plug the prior and likelihood into the Bayes' rules,</p>
<p>$$
P(\mu|D) = \frac{P(D|\mu)P(\mu)}{P(D)} =  \frac{\mu^{N_h} (1-\mu)^{N-N_h} \mu^{a-1} (1-\mu)^{b-1}}{P(D) B(a, b)} = \frac{\mu^{N_h+a-1} (1-\mu)^{N+b-N_h-1}}{P(D) B(a, b)}
$$</p>
<p>and</p>
<p>$$
P(D) = \int_0^1 \frac{\mu^{N_h+a-1} (1-\mu)^{N+b-N_h-1}} {B(a, b)} d\mu = \frac{B(N_h +a, N+b-N_h)}{B(a, b)}
$$</p>
<p>So we have</p>
<p>$$
P(\mu|D) = Beta(\mu| N_h + a, N+b-N_h)
$$</p>
<p>In summary, before we see data, we have some beliefs about $\mu$ governed by $Beta(\mu|a, b)$. After seeing the data, the probability of $\mu$ now is updated via $Beta(\mu| N_h + a, N+b-N_h)$, which can be served as the prior for the next new observations.</p>
<h3 id="incremental-updating">Incremental Updating</h3>
<p>For independent data we can update the hyperparamters incrementally, we consider an individual data at a time so that,</p>
<p>$$
P(\mu|X_1) = \frac{P(X_1|\mu)P(\mu)}{P(X_1)}
$$</p>
<p>$$
P(\mu|X_2, X_1) = \frac{P(X_2, X_1|\mu)P(\mu)}{P(X_2, X_1)} = \frac{P(X_2|\mu)P(X_1|\mu)P(\mu)}{P(X_2)P(X_1)} = \frac{P(X_2|\mu)P(\mu|X_1)}{P(X_2)}
$$</p>
<p>It&rsquo;s clear that the previous posterior now becomes the prior for the next piece of data.</p>
<h3 id="poisson-distribution">Poisson Distribution</h3>
<p>Poisson distribution measures the probability of a given number of events occuring in a specific time range,  which is given by,</p>
<p>$$
Pois(N;\theta) = \frac{e^{-\theta}\theta^N}{N!}
$$</p>
<p>where $N$ is the number of occurences in a time slot and $\theta$ is the parameter of interest. For example, we want to know the rate of traffic along a road between 8am and 9am, so $N$ is the number of cars and $\mu$ is the rate of traffic per hour.</p>
<h4 id="gamma">Gamma</h4>
<p>Then we have Gamma distribution as our prior,</p>
<p>$$
P(\theta) = \Gamma(\theta|a, b) = \frac{b^a \theta^{a-1} e^{-b\theta}}{\Gamma(a)}
$$</p>
<p>so the posterior after seeing the first piece of data is</p>
<p>$$
P(\theta|N_1) = \frac{P(N_1|\theta)P(\theta)}{P(N_1)} = \frac{b^a}{\Gamma(a) N_1! P(N_1) }e^{-(b+1)\theta} \theta^{N+a-1} \propto e^{-(b+1)\theta} \theta^{N_1+a-1}
$$</p>
<p>we can see that the posterior is also a Gamma distribution with $a_1 = a + N_1$ and $b_1 = b + 1$.</p>
<h3 id="multinominal-distribution">Multinominal Distribution</h3>
<p>In the case of Bernoulli, we only consider two outcomes: 0 or 1. But what if we have 3 or more outcomes? Well, we use multinominal distribution, which is the generalization of the binominal distribution. Suppose we have a $k$-sided dice with the probability of $\mu_k$ for $x^k = 1$, and we roll the dice $N$ times, so there are $N$ independent observations $x_1, x_2, &hellip;, x_n$, the multinominal distribution are given by,</p>
<p>$$
M(m_1, m_2, &hellip;, m_k|\mu, N) = \frac{N!}{m_1!m_2!&hellip;m_k!} \prod_{k=1}^K \mu_k^{m_k}
$$</p>
<p>where  $m_k=\sum_n^Nx_n^k$ represents the number of $x_n^k = 1$.</p>
<h4 id="dirichlet">Dirichlet</h4>
<p>TODO</p>
<h2 id="discriminal-vs-generative-models">Discriminal vs Generative Models</h2>
<p>Take the problem mentioned in the introduction as an example, suppose we have 2 classes, &lsquo;cat&rsquo; and &lsquo;dog&rsquo;, and we want to know which class the new image belong to. The problem is to find the probability $P(C=cat|x)$ and $P(C=dog|x)$, and then we classify the image into the class with the largest probability.</p>
<p>Usually, we think of our observations as given and the predictions as random variables, and we model the target variable as a function of the predictors. This is known as discriminal model. In this example, we could use logistic regression to make a classification, and the corresponding probability can be computed using a sigmoid function</p>
<p>$$
P(C=cat|X)=\frac{1}{1 + e^{-(wx + b)}}
$$</p>
<p>However, we can also consider both features and target variables at the same time. Using the Bayes' rule below, we can calculate $P(Y|X)$ in another way,</p>
<p>$$
P(C=cat|X) \propto P(X, C=cat)= P(X|C=cat)P(C=cat)
$$</p>
<p>This is known as generative model, where we use Bayes' rule to turn $P(X|Y)$ into $P(Y|X)$.</p>
<p>In discriminal model, we don&rsquo;t need the prior of classes, so there are less parameters to be determined. Also, it might have a better performance if the estimate for that prior is far away from the true distribution.</p>
<h2 id="graphical-models">Graphical Models</h2>
<p>Given 2 random variables, $X$ and $Y$, they could be dependent directly or not. Even if they are not dependent directly, typically there is still correlation between them. If they are correlated, then</p>
<ul>
<li>X could affect Y</li>
<li>Y could affect X</li>
<li>X has no direct effect on Y, but they could be both affected by another random variable Z</li>
</ul>
<p>We can describe the above relationships using a graph, where each node represents a random variable and the links between nodes show that relationship. The above three relationships are captured by the following figure,</p>
<p>
  <figure>
    <img src="/blog/post/images/bayesian-network.png" alt="">
    <figcaption>Figure 1: Directed graphical models representing the above three conditions </figcaption>
  </figure>
</p>
<p>Such a graph is known as Bayesian networks where we use a directed graph to show causal relationships between random variables. Specifically, we add directed links between $X$ and $Y$ if $X$ directly influences $Y$ shown in the left graph of Figure 1.</p>
<h3 id="conditional-independence">Conditional Independence</h3>
<p>The left and middle graphs of Figure 1 are easy to understand since they only have two variables, and they are denoted by $P(Y|X), P(X|Y)$ respectively. However, the last one with three variables, $X, Y, Z$, is a bit tricky. Let&rsquo;s first consider the conditional distribution of $X$ given Z and Y, we have</p>
<p>$$
P(X|Z, Y) = P(X|Z)
$$</p>
<p>If we further consider the joint distribution of X and Y conditioned on Z, then we have</p>
<p>$$
P(X, Y|Z) = \frac{P(X, Y, Z)}{P(Z)} = \frac{P(Z) P(Y|Z)P(X|Z, Y)}{P(Z)} = P(X|Z)P(Y|Z)
$$</p>
<p>This is called conditional independence, which means that X and Y are statistically independent, given Z. From the view of a graphical model, we can see that there is no direct link between X and Y shown in the right graph of Figure 1.</p>
<h2 id="latent-dirichlet-allocation">Latent Dirichlet Allocation</h2>
<p>Now let&rsquo;s learn a topic modeling method that utilises the knowledge we&rsquo;ve talked about so far, Latent Dirichlet Allocation(LDA). Note this is not linear discriminant analysis, which is also abbrivated to LDA. Here, LDA is an unsupervised learning method that is used to model topics within a set of documents. Speaking of &lsquo;topic&rsquo;, it means that when you find a group of words occuring many times in an article, such as &lsquo;banana, apple, fruit, vegetable&rsquo;, you will relate them to an area, like &lsquo;Food&rsquo; in this case.</p>
<h3 id="latent">Latent</h3>
<p>In LDA, documents are represented as a fixed group of topics, which are unknown as latent variables. And these topics are characterized by a small specific set of words. For example, words like &lsquo;teacher, student, school, exam, marks&rsquo; should occur more frequently in the area of Education than topics like Sports. This means <strong>different topics have different word distribution</strong>, as shown in Figure 2.</p>
<p>
  <figure>
    <img src="/blog/post/images/topic-word.png" alt="">
    <figcaption>Figure 2: Word distribution varies in different topics</figcaption>
  </figure>
</p>
<p>If a document contains more words like &lsquo;teacher, school&rsquo;, it&rsquo;s likely to be identified as &lsquo;Education&rsquo;. But it could contain other topics. For example, if this is a document regarding a sports contest held in a school, then it&rsquo;s much likely to be associated with &lsquo;Sports&rsquo; rather than &lsquo;Education&rsquo;. Thus, we can see that a document can also contain different topics with different weights, i.e. each document has its own topic distribution.</p>
<p>From above, we know that a document consists of a group of topics, and each topic has its special words.   To generate a document, we can randomly choose N topics for N words in a document and then randomly choose a word from the corresponding topic. Of course, such an article contains little meaning since we ignore the order and semantics of words. But it&rsquo;s reasonable for LDA since LDA treats documents just as a bag of words(BOW).</p>
<h3 id="dirichlet-1">Dirichlet</h3>
<p>So the topic-word distribution and doc-topic distribution are the unknown parameters we want to find, but there are many possible values for them. Again, we need a right prior to describe this uncertainty of the values, but which prior should we use?</p>
<p>Remember that we draw a topic from $K$ topics for each word in a document with $N$ words, it means there are $K$ possbile outcomes available for each word, and we repeat this process $N$ times, so it&rsquo;s a multinominal distribution. And this is true for drawing a word from that topic with $V$ words. Furthermore, we&rsquo;ve known that the cojugate prior of the multinominal distribution is Dirichlet distribution, so Dirichlet distribution is chosen as our prior, where</p>
<ul>
<li>doc-topic distribution follows $\theta^d \sim Dir(\alpha)$</li>
<li>topic-word distribution follows $\phi^t \sim Dir(\beta)$</li>
</ul>
<h3 id="allocation">Allocation</h3>
<p>To sum up, the whole process of generating a document in LDA is illustrated in Figure 3,</p>
<p>
  <figure>
    <img src="/blog/post/images/LDA.png" alt="">
    <figcaption>Figure 3: Graphical model for LDA</figcaption>
  </figure>
</p>
<p>The figure looks a bit scary, well, let&rsquo;s start with some notations first,</p>
<ul>
<li>$M=|D|$, the number of documents
<ul>
<li>$D={d_1, d_2, &hellip;, d_M}$,  where $d_i$ represents $i_{th}$ document</li>
</ul>
</li>
<li>$V=|W|$, the number of vocabulary appeared in all documents
<ul>
<li>$W={w_1, w_2, &hellip;, w_V}$,  where $w_i$ represents $i_{th}$ word</li>
</ul>
</li>
<li>$K = |T|$, the number of topics
<ul>
<li>$T={t_1, t_2, &hellip;, t_K}$, where $t_k$ represents $k_{th}$ topic</li>
</ul>
</li>
<li>$N_{d}$, the number of words in a document $d$</li>
<li>$\bold w^{d}={w_1^{d}, w_2^{d}, &hellip;, w_{N_{d}}^{d}}$, where $w_i^{d}$ represents $i_{th}$ word in a document $d$</li>
<li>$\theta^d$ is a probability vector, which represents the distribution of topics in a document $d$
<ul>
<li>$\Theta = (\theta^d|d \in D)$</li>
</ul>
</li>
<li>$\phi^t$ is a probability vector, which represents the distribution of words associated with a topic $t$
<ul>
<li>$\Phi = (\phi^t|t \in T)$</li>
</ul>
</li>
<li>$\bold t^{d} = t_1^{d}, t_2^{d}, &hellip;, t_{N_{d}}^{d}$, where $t_i^{d}$ represents a topic drawn from $\theta^d$</li>
</ul>
<p>From Figure 3, the joint distribution of the hidden and observed variables for a single document is given by,</p>
<p>$$
p(\bold t^d, \bold w^d, \theta^d, \Phi|\alpha, \beta) = P(\theta^d|\alpha) P(\Phi|\beta) P(\bold  t^d, \bold w^d|\theta^d, \Phi) = P(\theta^d|\alpha) P(\Phi|\beta) \prod_n^{N_d} P(  t_n^d, w_n^d|\theta^d, \Phi)
$$</p>
<p>$$
= P(\theta^d|\alpha) P(\Phi|\beta) \prod_n^{N_d} P(t_n^d |\theta^d, \Phi) P(w_n^d|t_n^d, \theta^d, \Phi)
$$</p>
<p>$$
= P(\theta^d|\alpha) P(\Phi|\beta) \prod_n^{N_d} P(t_n^d|\theta^d) P(w_n^d|\phi^{t_n^d})
$$</p>
<p>$$
= P(\theta^d|\alpha) \prod_t^TP(\phi^t|\beta) \prod_n^{N_d} P(t_n^d|\theta^d) P(w_n^d|\phi^{t_n^d})
$$</p>
<p>Our goal is to maximise this equation, but before that we need to eliminate the hidden variable $\bold t^d$,</p>
<p>$$
p(\bold w^d, \theta^d, \Phi|\alpha, \beta) = \int_{t^d} P(\theta^d|\alpha) P(\Phi|\beta) \prod_n^{N_d} P(t_n^d|\theta^d) P(w_n^d|\phi^{t_n^d})
$$</p>
<p>$$
= P(\theta^d|\alpha) P(\Phi|\beta) \prod_n^{N_d} \sum_{t_n^d=t_1}^{t_K} P(t_n^d|\theta^d) P(w_n^d|\phi^{t_n^d})
$$</p>
<p>There are two common ways to compute this: Gibbs sampling and variational inference.</p>
<h3 id="gibbs-sampling">Gibbs Sampling</h3>
<p>TODO</p>
<h3 id="variational-inference">Variational inference</h3>
<p>TODO</p>
<h2 id="references">References</h2>
<ul>
<li><a href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/">http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/</a></li>
<li><a href="https://www.mygreatlearning.com/blog/understanding-latent-dirichlet-allocation/">https://www.mygreatlearning.com/blog/understanding-latent-dirichlet-allocation/</a></li>
</ul>




        
      </article>

      
      <aside class="article-aside">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#probability">Probability</a></li>
    <li><a href="#bayes-inference">Bayes' Inference</a>
      <ul>
        <li><a href="#pros-and-cons">Pros and cons</a></li>
        <li><a href="#map">MAP</a></li>
        <li><a href="#mle">MLE</a></li>
      </ul>
    </li>
    <li><a href="#conjugate-prior">Conjugate Prior</a>
      <ul>
        <li><a href="#bernoulli-distribution">Bernoulli Distribution</a></li>
        <li><a href="#incremental-updating">Incremental Updating</a></li>
        <li><a href="#poisson-distribution">Poisson Distribution</a></li>
        <li><a href="#multinominal-distribution">Multinominal Distribution</a></li>
      </ul>
    </li>
    <li><a href="#discriminal-vs-generative-models">Discriminal vs Generative Models</a></li>
    <li><a href="#graphical-models">Graphical Models</a>
      <ul>
        <li><a href="#conditional-independence">Conditional Independence</a></li>
      </ul>
    </li>
    <li><a href="#latent-dirichlet-allocation">Latent Dirichlet Allocation</a>
      <ul>
        <li><a href="#latent">Latent</a></li>
        <li><a href="#dirichlet-1">Dirichlet</a></li>
        <li><a href="#allocation">Allocation</a></li>
        <li><a href="#gibbs-sampling">Gibbs Sampling</a></li>
        <li><a href="#variational-inference">Variational inference</a></li>
      </ul>
    </li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
      
      </aside>
    </div>
    
    
    
    
      

    
  </div>

    <footer>
  

<div class="social-icons">
  
    
    
      
      <a href="mailto:?to=xiaopan.wpp@outlook.com" name="Email">
        <em class="fas fa-envelope"></em>
      </a>
    
       &nbsp;&nbsp;&nbsp;
      <a href="https://github.com/ixiaopan" name="GitHub">
        <em class="fab fa-github"></em>
      </a>
    
       &nbsp;&nbsp;&nbsp;
      <a href="https://www.linkedin.com/in/ixiaopan" name="Linkedin">
        <em class="fab fa-linkedin"></em>
      </a>
    
       &nbsp;&nbsp;&nbsp;
      <a href="https://space.bilibili.com/22910840" name="Bilibili">
        <em class="fab fa-youtube"></em>
      </a>
    
  

  
</div>


  
  <div class="container">
    <p class="credits copyright">
      <a href="https://ixiaopan.github.io/blog/about">ixiaopan</a>
      &nbsp;&copy;
      2021
      
      &nbsp;&ndash;&nbsp;
      <em class="fas fa-moon" id="dark-mode-toggle"></em>
    </p>

    <p class="credits theme-by">
      Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;
      Theme
      <a href="https://github.com/matsuyoshi30/harbor">Harbor</a>
    </p>
  </div>
</footer>

  </body>
</html>
