[
    
        
            {
                "ref": "https://ixiaopan.github.io/blog/post/ensemble-methods/",
                "title": "Ensemble Methods",
                "section": "post",
                "date" : "2021.04.20",
                "body": "Ensemble means a group of people or a collection of things. Ensemble methods means rather than using a single model, we will use a group of different models to gain a better prediction. In fact, ensemble methods usually defeat other models in Kaggle competitions. In this post, we will talk about the most popular ensemble methods , including voting, bagging, and boosting.\nVoting ensemble In real life, we often take advices from many people. For example, suppose you want to know whether a movie is worthwhile, you may ask your friends who\u0026rsquo;ve watched to give the movie a score(out of 5), say 3, 3, 2, 2, 2, 4. Since 5 people gave a score that is lower than 4, you may think about choosing another movie, let\u0026rsquo;s say Avatar. Then you ask your friends again and have some scores like this 5, 5, 5, 5, 5. Wow! All of your friends think that Avatar is an amazing movie that should certainly not be missed. Finally, you decide to watch Avatar. From this example, we can see that gathering plenty of opinions are likely to lead an informed decision.\nThe method used in this example to decide whether to watch a movie or not is known as voting. For classification, there are 2 types of voting named hard voting and soft voting. Hard voting returns the most popular class shown in Figure 1 while soft voting averages the probability of each class and then return the class that has the maximum probability. For regression, we simply average all the predictions.\n  Figure 1: Hard voting classifier predicitons (Hands-on machine learning, 2019)  Hard Voting Soft Voting Average for Regression Bagging bootstrap\nrandom forest\nBoosting References [1] A. Géron, Hands-on machine learning with Scikit-Learn and TensorFlow. Sebastopol (CA): O\u0026rsquo;Reilly Media, 2019.\n"
            }
        
    ,
        
            {
                "ref": "https://ixiaopan.github.io/blog/post/decision-tree/",
                "title": "Decision Tree",
                "section": "post",
                "date" : "2021.04.19",
                "body": "The way decision tree works is similar to the way we make decisions in real life. For example,when you are going to watch a movie, you might have some questions on your head, such as \u0026lsquo;Is it a fiction movie? Is it directed by David Fincher?\u0026rsquo;\n  Figure 1: The process of movie selection  From Figure 1, we can see that a decision tree builds a binary tree to partion the data. Each node is a decision rule based on a feature and the tree can grow endlessly. Two questions then arise:\n How is the decision rule made? How deep is the decision tree?  Decision Rule Since there are so many features and each feature can have different values, we have to loop over all of them and find the best split. Well, how to measure the performance of a split? There are 3 measures widely used — Gini Impurity, Entropy, and Information Gain.\nGini Index Gini Index, also known as Gini Impurity, measures how often a randomly selected element from the set is classified incorrectly.\n$$ Q_m^g(L) = \\sum_{c \\in C } p_c(L) (1 - p_c(L)) = 1 - \\sum_{c \\in C } p_c(L)^2 $$\nwhere $L$ is short for the children node and $P_c(L)$ is the faction of class $c$ in the leaf node $L$,\n$$ p_c(L) = \\frac{1}{|L|} \\sum_{x, y \\in L} [y == c] $$\nwhere $[y == c] = 1$ if $y$ belongs to class $c$ and 0 otherwise.\n  Figure 2: The plot of Gini Index  Figure 2 shows that the value of Gini Index is the lowest at the start and end of the x-axis and maximum at the middle of the x-axis. In other words,\n If the leaf node only has one class, then this node is a pure node and the gini impurity of this leaf node is 0. On the other hand, if all elements in this leaf node belong to an individual class, then the Gini Index of this node has the maximum value of $ 1 - 1/len(L) $.  Entropy Entropy is a concept of Information Theory. Before introducing the entropy, we should have a little understanding of information.\nInformation is related to the surprise in some way. For example, if I told you that you will go to work tomorrow. Well, that\u0026rsquo;s not surprising because you work every day. However, if I told you that tomorrow is the end of the world, you are likely to be shocked because it is an breaking news.\nWe can measure this surprise by the following equation\n$$ I(x) = -log(p(x)) $$\nIf an event is unlikely to happen, then $p(x)$ is close to 0 and $I(x)$ tends to be infinity, which means it conveys much information since impossible things happened and it must have a significant implication behind it.\nThen what\u0026rsquo;s the entropy? The previous equation calculate the information contained in one outcome. However, it\u0026rsquo;s quite often to have many outcomes for a random variable $X$. Therefore, the expected information over all outcomes is defined as the entropy.\n$$ H(X) = E_{x \\in X}[-log(p(x)] $$\nIn this case, the classes in the leaf node is the random variable $X$ and the probability of each outcome is the fraction of each class, which is expressed as\n$$ Q_m^e(L) = \\sum_{c \\in C}- p_c(L) log(p_c(L)) $$\nIn a word, entropy measures the randomness of a set. Lower entropy means a purer set while higher entropy means there are more other classes that is not the class $c$ in a set.\nInformation Gain Information Gain is simply the difference between the impurity of the parent node $A$ before splitting and the sum of impurity of all children nodes after splitting. It measures how much the impurity of a set $A$ were reduced after splitting. The larger the information gain is, the better the split is.\n$$ IG(A) = H(A) - \\sum_{L \\in children \\ nodes} p(L) H(L) $$\nIn summary, when a decisiton tree makes a split on a feature, it tries to achieve,\n a lower impurity a lower entropy a higher information gain  CART CART is short for classification and regression tree algorithm, which is used to train Decisioin Trees. CART tries to find the best split that produces purest subsets by calculating the weighted Gini Impurity on each split made by each feature $k$ from the parent node\u0026rsquo;s training sample and corresponding threshold $t_k$.\nSpecifically, it tries to minimize the following loss function for a classification task,\n$$ L(k, t_k) = \\frac{|C_m^L|}{|N_m|}Q_m^G(C_m^L) + \\frac{|C_m^R|}{|N_m|} Q_m^G(C_m^R) $$\nwhere $C_m^L$ and $C_m^R$ are children nodes splitted on node $N_m$.\nFor a regression task, it minimizes the sum of squred error\n$$ L(k, t_k) = \\frac{|C_m^L|}{|N_m|}SSE(C_m^L) + \\frac{|C_m^R|}{|N_m|} SSE(C_m^R) $$\nwhere $SSE(subset)$ is defined as\n$$ SSE(subset) = \\sum_{n \\in subset} (y_n - \\overline y)^2 $$\n$$ \\overline y = \\frac{1}{|subset|} \\sum_{n \\in subset} y_n $$\nPrunning Now let\u0026rsquo;s address the second problem, i.e. when to stop growing the tree. You can either stop growing the tree when you build the tree or trim the tree after building, which are known as pre-pruning and post-pruning respectively.\nPre-pruning Scikit-learn provides several hyperparameters to do a pre-pruning:\n the maximum depth the minimum number of the samples a node must have to split the minimum number of the samples in a leaf node the maximum number of leaf nodes  All of these parameters can be tuned with cross-validation.\nPost Pruning Though pre-pruning is straightforward, it is a bit short-sighted since it doesn\u0026rsquo;t build a full tree and there might be some splits works better later on. Therefore, it would be better to have a large and full-size tree and then we trim some useless branches to get a better substree. Cost complexity pruning, also known as weakest link pruning, is one way to do this.\nPros and Cons Advantages:\n Decision trees are simple and intutive to interpret, and we can easily visualize the process of decision making. They can be used for both classification and regression. There is no need to normalize or scale data. They can help to understand what features are most important.  Disadvantages:\n They can be easy to overfit. They are sensitive to variations of training data. If you rotate the same data, you will get a completely different tree because all splits are perpendicular to an axis.    Figure 3: senstivity to variations of training set (Hands-on machine learning 2019)  References [1] A. Géron, Hands-on machine learning with Scikit-Learn and TensorFlow. Sebastopol (CA): O\u0026rsquo;Reilly Media, 2019.\n[2] pruning-decision-trees, Kaggle\n[3] how-to-choose-alpha-in-cost-complexity-pruning\n[4] Cost-Complexity Pruning\n"
            }
        
    ,
        
            {
                "ref": "https://ixiaopan.github.io/blog/post/linear-regression-02/",
                "title": "Linear Regression 02",
                "section": "post",
                "date" : "2021.04.17",
                "body": "In the last post, we talked about simple linear regression. However, we only considered one predictor. In fact, it\u0026rsquo;s quite common to have mulitple attributes in real-world problems. For example, if we want to predict the price of a car, we have to consider many factors like car size, manufacturer and fuel type. Clearly, the simple linear regression is not suitable for this case. Therefore, we need to extend it to accommodate multiple predictors.\nMultiple Linear Regression Suppose we have a data set with the size of $n$, and each data point has $d$ dimensions. Then the input data is denoted by $X \\in R^{n \\times d}$, and the parameters and targets are denoted by $\\bold w \\in R^d$, $\\bold y \\in R^n$ respectively. Thus, the loss function can be written by the following equation:\n$$ L = \\sum_i^{n} (\\bold x_i \\bold w - \\bold y_i)^2 = (\\bold X \\bold w - \\bold y)^T(\\bold X \\bold w - \\bold y) $$\n$$ = \\bold w^T\\bold X^T \\bold X \\bold w - \\bold y^T \\bold X \\bold w - \\bold w^T \\bold X^T \\bold y + \\bold y^T \\bold y $$\n$$ = \\bold w^T\\bold X^T \\bold X \\bold w - 2 \\bold w^T \\bold X^T \\bold y + \\bold y^T \\bold y $$\nThen we take the derivative of $L$ with respect to $\\bold w$ as simple linear regression before. Well, we need to know a little bit about the matrix calculus\n$$ \\frac{\\partial}{\\partial \\bold x} \\bold x^TA\\bold x = (A + A^T)\\bold x $$\n$$ \\frac{\\partial}{\\partial \\bold x} A^T \\bold x = A $$\nThe gradient of $L$ can be seen easily\n$$ \\frac{\\partial}{\\partial \\bold x } L = (2\\bold X^T\\bold X)\\bold w - 2 \\bold X^T\\bold y $$\nSetting this gradient to zero,\n$$ \\bold w= (\\bold X^T\\bold X)^{-1} \\bold X^T \\bold y $$\nHowever, this equation is unlikely to work if $\\bold X^T\\bold X$ is not invertible(singular), such as if the number of features are more than the number of observations($n \u0026lt; d$). One way to solve this equation is to use SVD.\npseudoinverse SVD technique can decompose any matrix $A$ into the matrix multiplication of three matrices $U\\Sigma V^T$. Thus the above equation can be written in the following form\n$$ \\bold w = A^+y $$\n$$ A^+ = (\\bold X^T\\bold X)^{-1} \\bold X^T = V\\Sigma^{-1}U^T $$\nIn practice, the algorithm will set the elements of $\\Sigma$ that less than a smaller threshold to zero, then take the inverse of all nozero values, and finally transpose the resulting matrix i.e. $(U\\Sigma V^T)^{-1}$\nProbabilistic Interpretation It\u0026rsquo;s inevitable to introduce errors when we collect data. The error could be systematic errors, human errors or something else. We can define the error to be $\\epsilon_i$ for each observation.\n$$ y_i = a + bx_i + \\epsilon_i $$\nThe assumption of linear regression is that the expected error is zero. Specifically, the error follows the Gaussian distribution with the mean of zero and variance of $\\sigma^2$.\n$$ \\epsilon_i \\sim N(0, \\sigma^2) $$\nThus, the probability of $y_i$ is defined by the predictors $x_i$ and the paramters $a, b, \\sigma^2$.\nMLE We have found the parameters by minimizing the loss, but now we are going to use another method to derive the same result, which is known as maximum likelihood estimation(MLE).\nThe basic idea of MLE is that if the data were generated from some model, then what\u0026rsquo;s the parameters of the model were most likely to make this happen? In other words, we are finding the parameters that maximize the probability of the data $D$ that we\u0026rsquo;ve seen.\nSuppose we have a data set of inputs $X={x^{(1)}, x^{(2)}, \u0026hellip;, x^{(N)}}$ and corresponding target variables ${y_1, y_2, .., y_N}$ with a Gaussian noise $\\epsilon$. Then we can construct the likelihood of all data points,\n$$ L(\\theta|D) = \\prod_{n=1}^N p(y_i|x_i, a, b, \\sigma^2) $$\nUsually, we will take the log likelihood to make computation more simpler,\n$$ In(L(\\theta|D)) =\\sum_i^n In(\\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{(y - a - bx_i)^2}{2\\sigma^2}}) $$\n$$ = \\frac{N}{2}In\\sigma - \\frac{N}{2}In2\\pi - \\frac{1}{2\\sigma^2}\\sum_{n=1}^N(y_i - a - bx_i)^2 $$\nFrom above equation, we can see that maximizing the likelihood is equivalent to minimizing the sum of squared error.\nGeometry of Linear Regression In this section, we will look at the geometry of the linear regression. In $N$-dimensional space whose axes are the values of $y_1, y_2, \u0026hellip;, y_n$ , the least-squares solution is obtained by finding the orthogonal projection of the target vector $y$ onto the subspace spanned by the columns of $X$.\n  Figure 1: Geometry interpretation of the least-squares solution (PRML 2006)  From the following matrix form, we can see that the predicted value $\\bold y'$ lies the column space of $X$. If the true target value $\\bold y$ also lies in this space, then the loss of linear regression is zero, which is never the case in real life.\n$$ \\displaystyle{\\bold y' = \\bold X \\bold w = \\begin{bmatrix}1\u0026amp;x_{11} \u0026amp; x_{12} \u0026amp; \u0026hellip; \u0026amp; x_{1d}\\\\ 1\u0026amp;x_{21} \u0026amp; x_{22} \u0026amp; \u0026hellip; \u0026amp; x_{2d}\\\\ \u0026hellip; \\\\ 1\u0026amp;x_{n1} \u0026amp; x_{n2} \u0026amp; \u0026hellip; \u0026amp; x_{nd} \\end{bmatrix} \\begin{bmatrix}w_0\\\\ w_1\\\\ w_2\\\\ \u0026hellip;\\\\ w_d \\end{bmatrix} } $$\nReferences [1]C. Bishop, Pattern Recognition and Machine Learning. 2006.\n"
            }
        
    ,
        
            {
                "ref": "https://ixiaopan.github.io/blog/post/bias-variance-dilemma/",
                "title": "Bias-Variance dilemma",
                "section": "post",
                "date" : "2021.04.15",
                "body": "When you learn more about machine learning, you must hear people talking about high bias or high variance something like that. What does they mean by \u0026lsquo;high bias\u0026rsquo; or \u0026lsquo;high variance\u0026rsquo;?\nActually, when I first heard these terms, I was completely confused. Even though I tried to find the answer on Google, I still had no idea until I took the Advanced Machine Learning module in semester 2. Therefore, I\u0026rsquo;m writing this post to try to explain this. I hope this post can help people who are still struggling with them understand the two most important concepts clearly.\nGeneralization Error The underlying assumption of machine learning is that there are some relationships between data. However, we are not able to know this true function, otherwise there is no need to learn it.\nSuppose we have a true realtionship denoted by $f(x)$ (the red dot in Figure 1), and we want to construct a machine denoted by $f'(x)$ to approximate the true function based on the data $D$ sampled from the population $\\chi$.\nThe training loss is defined by the following equation, where $f'(x|D)$ is the machine we learn from this particular data set $D$\n$$ L_T(D) = \\sum_{x\\in D}(f'(x|D) - f(x))^2 $$\nHowever, our goal is to know how well this machine works on unseen data, which is known as generalization. The generalization loss is expressed as\n$$ L_G(D) = \\sum_{x\\in \\chi} p(x) (f'(x|D) - f(x))^2 $$\nIf we have another data set $D_1$, then we will get another machine $f'(x|D_1)$ and another generalization loss $L_G(D_1)$ shown in Figure 1.\n  Figure 1: Generalisation error  We can see that the generalization loss is depend on our training data. Thus, the generalization loss for a particular data set doesn\u0026rsquo;t make much sense. Instead, the average generalization loss over all the data set with the same size of $n$ is what we expect.\n$$ E_G = E_D[L_G(D)] = E_D[\\sum_{x\\in \\chi} p(x)(f'(x|D) - f(x))^2] $$\nMean Machine We have already known that there is a different machine $f'(x|D)$ for a given data set $D$. Thus, for an unseen data $x$, we will have many predictions of many different machines, which are represented in blut dots shown in Figure 2.\n  Figure 2: Bias and variance  The average prediction for an unseen data is the mean prediction(the yellow dot in Figure 2).\n$$ f'_m(x) = E_D[f'(x|D)] $$\nBias Bias is the distance between the mean prediction(the yellow dot) and the true value(the red dot) shown in Figure 2. High bias implies that our model is too simple and the prediction value is much far away from the true value.\n$$ B = \\sum_{x \\in \\chi} p(x) (f\u0026rsquo;m - f(x))^2 $$\nVariance Variance measures the variation in the prediction of the machine when we change different data set we train on. If we have a complex machine, as mentioned earlier, the machine will try its best to match every data in training data set. In other words, the machine memorized the trainining data and a little change in data set will cause significant variation in prediction.\n$$ V = \\sum_{x \\in \\chi}p(x) E_D[ (f'(x|D) - f\u0026rsquo;m)^2 ] $$\nBias-Variance dilemma Now it\u0026rsquo;s time to decompose the average generalisation error. Let\u0026rsquo;s plug the $f'_m(x)$ into the previous equation\n$$ E_G = E_D[L_G(D)] = E_D[\\sum_{x\\in \\chi} p(x)(f'(x|D) - f(x))^2] $$\n$$ = E_D[\\sum_{x\\in \\chi}p(x) (f'(x|D) - f_m' + f_m' - f(x))^2] $$\n$$ = E_D[\\sum_{x\\in \\chi}p(x){(f'(x|D) - f_m')^2 + (f_m' - f(x))^2 + 2(f'(x|D) - f_m')(f_m' - f(x)) }] $$\nIt\u0026rsquo;s noticeable that the cross-term will cancel out because $f\u0026rsquo;m$ and $f(x)$ are constants no matter what data set $D$ is.\n$$ E_D[\\sum_{x\\in \\chi}p(x)2(f'(x|D) - f_m')(f_m' - f(x))] $$\n$$ = \\sum_{x\\in \\chi}p(x) (2E_D[f'(x|D)]-f\u0026rsquo;m)(f\u0026rsquo;m-f(x)) = 0 $$\nTherefore, we are left with\n$$ E_G = E_D[L_G(D)] = E_D[\\sum_{x\\in \\chi}p(x)(f'(x|D) - f_m')^2 + \\sum_{x\\in \\chi}p(x)(f_m' - f(x))^2] $$\n$$ = \\sum_{x\\in \\chi}p(x) E_D[(f'(x|D) - f_m')^2] + \\sum_{x\\in \\chi}p(x)(f_m' - f(x))^2 $$\n$$ = V + B $$\nIn summary,\n If our machine is too simple, then we might not be able to fit the training data. Since the machine knows little about the data, it\u0026rsquo;s unlikely to work well on unseen data. This means our model has a high bias. If our machine is too complex, then we might be able to fit the training data perfectly. It means that the machine knows too much about the data, even the noise that it should not learn. Thus, it\u0026rsquo;s too sensitive to training data so that a little change in data will cause a great variance. This means our model has a high variance.  Throughout the world of machine learning, we are always trying to find a balance between bias and variance.\n"
            }
        
    ,
        
            {
                "ref": "https://ixiaopan.github.io/blog/post/linear-regression-01/",
                "title": "Linear Regression 01",
                "section": "post",
                "date" : "2021.04.14",
                "body": "There are two main tasks in machine learning: regression and classification. Today we will talk about regression, more specifically, linear regression. Linear regression is simple and easy to understand and maybe it\u0026rsquo;s the first algorithm that most people learn in the world of machine learning. So let\u0026rsquo;s go!\nProblem statement Suppose you are a teacher, and you record some data about the hours students spent on study and the grades they achieved. Then you want to predict the grade for given hours that someone spent. Here are some sample data you collected:\n   Hours 0.5 1 2 3 4     Grade 20 21 22 24 25    Since there are only two variables, let\u0026rsquo;s plot them.\n  Figure 1: The scatter plot of hours and grade  Well, we can see that the variable grade is positive related to the variable hours. For simplicity, we can use a simple line(the red line in this figure) to approximate this relationship. And this is exactly our first simple linear model.\nSimple Linear Regression Remember a line equation is written in this way:\n$$ y = ax + b $$\nIn this example, $x$ is the variable hours and $y$ is the variable grade , which we already know. So the problem is how to calculate the parameter $a, b$. Technically, this is called parameter estimation. Usually, there are two ways to do this: minimising the loss and maximising the likelihood. Now we focus on the former.\nLoss What is the loss? Basically, it\u0026rsquo;s the error between the esitmated value and our true value. Minimising the error is simply to make the estimated value as close to the true value as possible.\n  Figure 2: The error of a single data (Bradthiessen.com 2021)  For a single data point, the loss function is defined below, where $y$ is the true value and $y'$ is our estimated value for a given $a, b$.\n$$ error = y_i - y'_i = y_i - ax_i - b $$\nSince we have many data points, we need to sum up them all to evaluate the overall errors.\n1. error Unfortunately, some error terms will cancel out when you do this calculation directly.\n$$ L = \\sum_i^n (y_i - y'_i) = \\sum_i^n (y_i - ax_i - b) $$\n2. the absolute value of error One way to tackle this is taking the absolute value of the error terms.\n$$ L = \\sum_i^n |y_i - y_i'| $$\nHowever, the absoulte value of $x$ is not differentiable at $0$.\n3. the squared value of error Instead of taking absolute value, we will square all the errors. One reason is that the errors will become larger and can be distinguished easily when squaring them. It looks like the errors are zoomed in and we can find them and minimize them quickly. It is also known as Residual Sum of Squares(RSS) or Sum of Squared Error (SSE).\n$$ L = \\sum_i^n (y_i - y_i')^2 $$\nPS: We will revisit the squared error later from the perspective of MLE.\nClosed-form solution Okay, finally we find a function to measure the loss. Next we need to find the parameters that minimize the squared error. Good news is that our loss function is differentiable and convex! It means that we have a global minimial value and can be calculated directly by taking derivatives.\nLet\u0026rsquo;s take the first derivatve of $b$\n$$ \\frac{\\partial L}{\\partial b} = \\sum_i^n -2(y_i - ax_i-b) $$\nand then set this equation to $0$,\n$$ -2(\\sum_i^ny_i -a\\sum_i^nx_i - \\sum_i^nb) = -2(n\\overline y-an\\overline x - nb) = 0 $$\n$$ b = \\overline y - a\\overline x $$\nLet\u0026rsquo;s take the first derivatve of $a$\n$$ \\frac{\\partial L}{\\partial a} = \\sum_i^n -2x_i(y_i - ax_i-b) $$\nand then plug $b$ into this equaiton and set this equation to 0 again,\n$$ \\sum_i^n -2x_i(y_i - ax_i-\\overline y+a\\overline x) = \\sum_i^n -2x_i[(y_i-\\overline y)- a(x_i -\\overline x)] $$\n$$ a = \\frac{\\sum_i^nx_i(y_i-\\overline y)}{\\sum_i^nx_i(x_i -\\overline x)} $$\nHere, we use a slight algebra trick,\n$$ a\\sum_i^n(x_i - \\overline x_i) = 0 $$\nThen we plug this into the previous equation\n$$ a = \\frac{\\sum_i^nx_i(y_i-\\overline y)}{\\sum_i^nx_i(x_i -\\overline x)} = \\frac{\\sum_i^nx_i(y_i-\\overline y) - \\sum_i^n\\overline x(y_i - \\overline y)}{\\sum_i^nx_i(x_i -\\overline x) - \\sum_i^n\\overline x(x_i - \\overline x)} $$\n$$ = \\frac{\\sum_i^n(x_i-\\overline x)(y_i-\\overline y)}{\\sum_i^n(x_i -\\overline x)^2} $$\n$$ = \\frac{Cov(x, y)}{Var(x)} $$\nFinally, we find the best estimators for simple linear regression.\n$R^2$ So how to evaluate our model? In other words, how good is it? We can use $R^2$ to measure our model. Let\u0026rsquo;s rewrite the previous equation by multiplying both the denominator and numerator by $\\sqrt {\\sum_i^n(y_i-\\overline y)^2}$\n$$ a = \\frac{\\sum_i^n (x_i - \\overline x)(y_i - \\overline y) \\sqrt {\\sum_i^n(y_i-\\overline y)^2}}{\\sqrt {\\sum_i^n(x_i-\\overline x)^2} \\sqrt {\\sum_i^n(x_i-\\overline x)^2} \\sqrt {\\sum_i^n(y_i-\\overline y)^2}} $$\n$$ a = R\\frac{s_y}{s_x} $$\nwhere\n$$ R = \\frac{Cov(x, y)}{\\sqrt{var(x)} \\sqrt{var(y)}} $$\n$$ s_y = \\sqrt{Var(y)} $$\n$$ s_x = \\sqrt{Var(x)} $$\nRemember that the error is defined as $e_i = y_i' - y_i$, so the mean of $e$ is\n$$ E(e) = \\frac{1}{N} \\sum_i^n e_i = \\frac{1}{N} \\sum_i^n b + ax_i - y_i =b + a\\overline x - \\overline y = 0 $$\nand the variance is\n$$ var(e) = \\sum_i^n (e_i - \\overline e)^2 = \\sum_i^n (y_i - b - ax_i)^2 = \\sum_i^n (y_i - \\overline y + a\\overline x - ax_i)^2 $$\nLet\u0026rsquo;s plug $a$ into this equation\n$$ var(e) = \\sum_i^n [(y_i - \\overline y) - R\\frac{s_y}{s_x}( x_i - \\overline x)]^2 = var(y) (1-R^2) $$\nOr you might be more familiar with this equation\n$$ R^2 = 1 - \\frac{var(e)}{var(y)} = 1 - \\frac{RSS}{TSS} $$\nTherefore, $R^2$ tells us how much variance of $y$ has been explained by our models. The higher the $R^2$ is, the better our model is.\nReferences [1]Bradthiessen.com, 2021. [Online]. Available: https://www.bradthiessen.com/html5/docs/ols.pdf. [Accessed: 14- Apr- 2021].\n[2] http://mlwiki.org/index.php/Linear_Regression\n"
            }
        
    ,
        
            {
                "ref": "https://ixiaopan.github.io/blog/post/descriptive-statistics/",
                "title": "Descriptive Statistics",
                "section": "post",
                "date" : "2021.04.13",
                "body": "In this post , I\u0026rsquo;m going to go through some basic concepts of statistics required in Data Science.\nThere are two main branches of statistics :\n  descriptive statistics tells us the statistics about the data like mean, mode and standard deviation, which you\u0026rsquo;ve learned in high school.\n  inferential statistics, on the other hand, uses a random dataset sampled from population to make inferences about population.\n  We will firstly focus on descriptive statistics, specifically, the central tendency and dispersion. Central tendency measures the center of the data while dispersion measures how spread out a given data is.\nCentral tendency Mean, mode and median are three mainly used measures of central tendency.\nMean Mean is the average of the data and calculated by summing up all data values and then dividing them by the number of data.\n$$ \\overline x = \\frac{\\sum_i^nx_i}{n} $$\nFor instance, say we have a group of data 1,2,3,4,5,6, the mean is 3.5.\nMedian Though mean is widely used, it\u0026rsquo;s sensitive to outliers. Suppose you have a set of data 1,2,3,4,5,6,100, after some calculations, you find that the mean is 17.28. However, it seems a bit strange since most of the data values is less than 10 except one extreme value 100, which stretches the distribution of the whole data set to the right. This is why median comes.\nTo get the median, firstly we need to sort the data in ascending order and then find the middle number that separate the data into two groups with the same size. In this example, the median is 4.\nMode Mode is the most frequent value. There could be one, two or more data values that have the same frequency and that freqency is the highest.\nDispersion Range Range is the distance between the maximum value and the minimum value. Again, range is sensitive to outliers.\n$$ r=max - min $$\nQuantile Quantiles are used to divide data into several equal-sized groups. The most widely used cut points are 0, 25, 50, 75, 100, denoted by min, Q1, Q2, Q3, max respectively.\nIQR or interquartile range measures where the central 50% of the data is.\n$$ IQR = Q3 - Q1 $$\nIQR can be used to detect outliers. Data that is greater than upper boundary or less than lower boundary can be considered as an outlier.\n$$ upper \\ boundary = Q3 + 1.5*IQR $$\n$$ lower \\ boundary = Q1 - 1.5*IQR $$\nVariance Deviation is the distance between a given data point and the mean. Since there are many data points, the variance calculates the average deviation from the mean.\nBut when you do this, you will always get a zero due to the definition of the mean.\n$$ \\sum_i^n d_i = \\sum_i^n (x_i - \\overline x) = \\sum_i^nx_i - n\\overline x = n\\overline x - n\\overline x = 0 $$\nFor simplicity, I omit the denominator n.\nOkay, let\u0026rsquo;s ignore the sign and use the absolute value of the deviation.\n$$ d_i = |x - \\overline x| $$\nThough it works, the most popularly used method is calculate the square of the deviation.\n$$ s^2 = \\frac{\\sum_i^n (x_i - \\overline x)^2}{n-1} $$\nThough variance works fine, the value is a bit hard to interpret. For instance, we have 15 records of fish size measured in kilogram:\n[ 2.1, 2.4, 2.4, 2.4, 2.4, 2.6, 2.9, 3.2, 3.2, 3.9, 4.5, 6.3, 8.2, 12.8, 23.5 ].\nThe variance is 30.97. It means that if we randomly catch a fish, its weight would be 30.97 squared kilogram far away from the average weight. Emm\u0026hellip;squared kilogram is an odd unit.\nStandard Deviation It\u0026rsquo;s simple to solve this problem by taking the square root of the variance, which is standard deviation.\n$$ s = \\sqrt{\\frac{\\sum (x - \\overline x)^2}{n-1}} $$\nSo the standard deviation in the previous example is 5.56kg, which makes much sense.\nDistribution Skewness Skewness measures the symmetry of a distribution. It\u0026rsquo;s quite common to have non-symmetric distributions.\n A left-/negative-skewed distribution\n it has a long left tail the mean is on the left of the median  A right-/positive-skewed distribution\n it has a long right tail the mean is on the right of the median  A skewed distribution implies that there are some special values that are larger/smaller than the common values. Let\u0026rsquo;s see an example.\n Figure 3.2 shows the histogram of the fish sizes gathered from a fisherman. We can see that this distribution is right-skewed. The majority of fish sizes are between 0 and 3kg and there are a few special fishes that weigh over 3.5kg. It also can be seen that the average weight(1.67kg) is a bit higher than the median(1.62kg) shown in Table 3.2.\nReferences [1] B. al., \u0026ldquo;Introduction to Statistics | Simple Book Production\u0026rdquo;, Courses.lumenlearning.com, 2021. [Online]. Available: https://courses.lumenlearning.com/introstats1. [Accessed: 14- Apr- 2021].\n"
            }
        
    
]