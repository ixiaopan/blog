<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<title>NLP - Text preprocessing</title>


  



<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link
  rel="alternate"
  type="application/rss+xml"
  href="https://ixiaopan.github.io/blog/index.xml"
  title=""
/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="NLP - Text preprocessing"/>
<meta name="twitter:description" content="From now on, we will focus on a specific domain — Natural Language Processing(NLP), in part because my summer project is about Named Entities Recognition(NER). Therefore, I need to know some text preprocessing techniques and have a good understanding of the state-of-art NLP models, particularly BiLSTM &#43; CRF. The very first step in NLP is text preprocessing, so I am going to start from here."/>



<link rel="stylesheet" href="https://ixiaopan.github.io/blog/fontawesome/css/all.min.css" />

<link
  id="dark-mode-theme"
  rel="stylesheet"
  href="https://ixiaopan.github.io/blog/css/dark.css"
/>

<script>
  var darkTheme = document.getElementById('dark-mode-theme')
  var storedTheme = localStorage.getItem('dark-mode-storage')
  if (storedTheme === 'dark') {
    darkTheme.disabled = false
  } else if (storedTheme === 'light') {
    darkTheme.disabled = true
  }
</script>

<script src="https://ixiaopan.github.io/blog/js/main.bundle.js"></script>
<script src="https://ixiaopan.github.io/blog/js/instantpage.min.js" type="module" defer></script>
<meta name="generator" content="Hugo 0.81.0" />
   
    
     <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
          delimiters: [
              {left: "$$", right: "$$", display: true},
              {left: "$", right: "$", display: false}
          ]
      });
  });
</script>

    
  </head>
  <body>
    
  




<header>
  <nav class="navbar">
  <div class="nav">
    
      <a href="https://ixiaopan.github.io/blog/" class="nav-logo">
        <img
          src="https://ixiaopan.github.io/blog/images/icon.JPG"
          width="50"
          height="50"
          alt="Logo"
        />
      </a>
    

    <ul class="nav-links">
      
        
          <li>
            <a href="/blog/about/" id="About"
              ><em class="fas fa-user fa-lg"></em
            ></a>
          </li>
          
      
        
          <li>
            <a href="/blog/search" id="Search"
              ><em class="fas fa-search fa-lg"></em
            ></a>
          </li>
          
      
        
          <li>
            <a href="/blog/archives" id="Archives"
              ><em class="fas fa-archive fa-lg"></em
            ></a>
          </li>
          
      
    </ul>
  </div>
</nav>


  
  
  <div class="intro-header">
    <div class="container">
      <div class="post-heading">
        
          <h1>NLP - Text preprocessing</h1>
        
        
        
          <span class="meta-post">
  <em class="fa fa-calendar-alt"></em
  >&nbsp;Jun 22, 2021
  
  &nbsp;&nbsp;<i class="fas fa-clock"></i>&nbsp;5 min  read

  
    &nbsp;&nbsp;&nbsp;<em class="fa fa-folder-open"></em>&nbsp;
    
      <a
        href="https://ixiaopan.github.io/blog/categories/nlp/"
        >NLP</a
      >&nbsp;
    
  
  
</span>

        
      </div>
    </div>
  </div>
  
</header>




    
  <div class="container" role="main">
    <div class="inner">
      <article class="article" class="blog-post">
        
  <p>From now on, we will focus on a specific domain — Natural Language Processing(NLP), in part because my summer project is about Named Entities Recognition(NER). Therefore, I need to know some text preprocessing techniques and have a good understanding of the state-of-art NLP models, particularly BiLSTM + CRF. The very first step in NLP is text preprocessing, so I am going to start from here.</p>
<h2 id="converting-text-to-lowercase">Converting text to lowercase</h2>
<p>For some letter-based languages such as English, letters could be either lowercase or uppercase, e.g. <code>book</code> , <code>Book</code> or <code>BOOK</code>. Since they represent the same word <code>book</code> with the same semantics, there is no need to encode them three times. The common way is to convert all words into a consistent written style — lowercase because of its readable and concise style.</p>
<p>However, this method sometimes could affect semantics of some specific words, for instance,  <code>May</code> and <code>may</code> are two different words. Well, for tasks that involve parts-of-speech analysis, it&rsquo;s a matter.</p>
<p>In python, it&rsquo;s easy to convert a string into lowercase,</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()
</code></pre></div><h2 id="removing-punctuation">Removing Punctuation</h2>
<p>For some tasks, punctuations such as <code>, . &quot; @ #</code> are meaningless to us, so we should remove them. In Python, we can do this using  the <code>sub()</code> method of the <code>re</code> module to replace any matched punctuation with an empty character</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#39;[,</span><span style="color:#ae81ff">\&#39;</span><span style="color:#e6db74">.!&#34;]&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, <span style="color:#e6db74">&#39;&#34;20.2 dollars! That</span><span style="color:#ae81ff">\&#39;</span><span style="color:#e6db74">s impossible&#34;, he said.&#39;</span>)
<span style="color:#75715e">#&gt;&gt; 202 dollars Thats impossible he said</span>

</code></pre></div><p>From the above code, we can see some issues,</p>
<ul>
<li>Abbreviation, <code>That's -&gt; Thats</code></li>
<li>Prices, <code>20.2 dollars -&gt; 202 dollars</code></li>
</ul>
<p>Maybe we can write some specific rules for a corpus to remove particular punctuations, but it will be time-consuming and inflexible.</p>
<h2 id="tokenization">Tokenization</h2>
<p>Tokenization is a technique to split a piece of text into a smaller unit. The unit could be</p>
<ul>
<li>a single word</li>
<li>a character</li>
<li>a combination of several words</li>
</ul>
<p>Why do we tokenize text? The answer is that the ultimate goal of tokenization is to build vocabulary for a corpus. After all, words in each sentence are ultimately from the vocabulary.</p>
<p>Okay, so how do we perform tokenization to get a sequence of words? A naive way is to split a string by whitespace shown below.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39; &#39;</span>)
</code></pre></div><p>However, there are some issues. For example, <code>United Kindom</code> will be split into two words,  <code>United</code> and <code>Kindom</code>. A common practice is to use the popular <a href="https://www.nltk.org/%5D">natural language toolkit (NLTK)</a> to do this</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize

tokens <span style="color:#f92672">=</span> word_tokenize(text)

</code></pre></div><p>With these tokens, how to build vocabulary? Usually, there are two ways to do this,</p>
<ul>
<li>include each uniqe token in the vocabulary</li>
<li>include only the top K frequently occurring tokens; the idea is that repetition usually conveys the most important information</li>
</ul>
<h2 id="stemming--lemmatization">Stemming &amp; Lemmatization</h2>
<p>In grammatical aspect, a word could have several variants to express tense, mood or something. For example,</p>
<ul>
<li><code>go, goes, went, gone</code> are different tenses of <code>go</code></li>
<li><code>higher, highest</code> are comparative and superlative form of <code>high</code></li>
</ul>
<p>In other words, these variants are originated from their <strong>root</strong> words. Generally, most words follow a general rule of to generate the corresponding forms, though there are some rare cases, as shown below,</p>
<ul>
<li><code>eat, ate, eaten</code></li>
<li><code>good, better, best</code></li>
</ul>
<p>Stemming and Lemmatization are two common methods to convert each word back to its original form or the root.</p>
<h3 id="stemming">Stemming</h3>
<p>Stemming is a simple and crude method that simply chopps off letters from the end of a word until <strong>a common root</strong> is found, which is the idea of Potter Stemming algorithm.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer, WordNetLemmatizer

words <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;run&#39;</span>, <span style="color:#e6db74">&#39;runner&#39;</span>, <span style="color:#e6db74">&#39;running&#39;</span>, <span style="color:#e6db74">&#39;ran&#39;</span>, <span style="color:#e6db74">&#39;runs&#39;</span>, <span style="color:#e6db74">&#39;easily&#39;</span>, <span style="color:#e6db74">&#39;saw&#39;</span>]
p_stemmer <span style="color:#f92672">=</span> PorterStemmer()
<span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> words:
    <span style="color:#66d9ef">print</span>(word <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;--&gt;&#39;</span> <span style="color:#f92672">+</span> p_stemmer<span style="color:#f92672">.</span>stem(word))

<span style="color:#75715e"># run--&gt;run</span>
<span style="color:#75715e"># runner--&gt;runner</span>
<span style="color:#75715e"># running--&gt;run</span>
<span style="color:#75715e"># ran--&gt;ran</span>
<span style="color:#75715e"># runs--&gt;run</span>
<span style="color:#75715e"># easily--&gt;easili</span>
<span style="color:#75715e"># saw--&gt;saw </span>
</code></pre></div><p>We can see that the result of stemming may not be a word, e.g. <code>easili</code>, and that the tense forms of some special words like <code>ran, saw</code> are not processed correctly.</p>
<h3 id="lemmatization">Lemmatization</h3>
<p>On the contrary, lemmatization returns the <strong>true root</strong> or <strong>lemma</strong> of a word by considering the whole vocabulary of a language and the context of that word in the sentence. In the case of <code>ran</code> and <code>saw</code>, the true root words or lemmas are <code>run</code> and <code>see</code> respectively.</p>
<p>NLTK provides a popular lemmatizer for us — WordNet Lemmatizer, which is an large lexical database of English. But before using it, we need to know the parts of speech of each word, which can also be done using <code>pos_tag()</code> method of NLTK.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># we mannually specify the parts of speech for each word</span>
words <span style="color:#f92672">=</span> [
(<span style="color:#e6db74">&#34;grows&#34;</span>, <span style="color:#e6db74">&#39;v&#39;</span>), (<span style="color:#e6db74">&#39;running&#39;</span>, <span style="color:#e6db74">&#39;v&#39;</span>), (<span style="color:#e6db74">&#34;better&#34;</span>, <span style="color:#e6db74">&#39;a&#39;</span>), (<span style="color:#e6db74">&#34;cats&#34;</span>, <span style="color:#e6db74">&#39;n&#39;</span>), (<span style="color:#e6db74">&#39;quickly&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>)
]

lemmatizer <span style="color:#f92672">=</span> WordNetLemmatizer()
[ lemmatizer<span style="color:#f92672">.</span>lemmatize(w, p) <span style="color:#66d9ef">for</span> w, p <span style="color:#f92672">in</span> words ]
<span style="color:#75715e"># [&#39;grow&#39;, &#39;run&#39;, &#39;good&#39;, &#39;cat&#39;, &#39;quickly&#39;]</span>
</code></pre></div><h2 id="removing-stopping-words">Removing stopping words</h2>
<p>It seems that we&rsquo;ve obtained the tokens as desired. But wait, let&rsquo;s plot the number of occurrence of each word.</p>
<p>
  <figure>
    <img src="/blog/post/images/tokens_counts.png#full" alt="">
    <figcaption>Figure 1: The top 10 frequently tokens</figcaption>
  </figure>

</p>
<p>Figure 1 shows the frequency of each token in the built-in NLTK corpus named <code>1789-Washington.txt</code>. It can be seen that most tokens are determiners, prepositions, conjuctions or other <strong>function words</strong> that have little lexical meaning. Obvisously, we need to remove them, which can be done easily using NLTK,</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords

stop_words_en <span style="color:#f92672">=</span> stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>)

tokens <span style="color:#f92672">=</span> [ w <span style="color:#66d9ef">for</span> w <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> w <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> stop_words_en ]

</code></pre></div><h2 id="putting-it-together">Putting it together</h2>
<p>So far, we&rsquo;ve introduced some basic and necessary text preprocessing techniques. Now let&rsquo;s put it together to build the whole text preprocessing pipeline.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> string<span style="color:#f92672">,</span> re
<span style="color:#f92672">import</span> nltk
<span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> wordnet
<span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
<span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
<span style="color:#f92672">from</span> nltk.tag <span style="color:#f92672">import</span> pos_tag
<span style="color:#f92672">from</span> nltk.stem.wordnet <span style="color:#f92672">import</span> WordNetLemmatizer


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_wordnet_pos</span>(tag):
    <span style="color:#66d9ef">if</span> tag<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#34;J&#34;</span>):
        <span style="color:#66d9ef">return</span> wordnet<span style="color:#f92672">.</span>ADJ

    <span style="color:#66d9ef">elif</span> tag<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#34;R&#34;</span>):
        <span style="color:#66d9ef">return</span> wordnet<span style="color:#f92672">.</span>ADV
    
    <span style="color:#66d9ef">elif</span> tag<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#34;V&#34;</span>): 
        <span style="color:#66d9ef">return</span> wordnet<span style="color:#f92672">.</span>VERB
    
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">return</span> wordnet<span style="color:#f92672">.</span>NOUN

lem <span style="color:#f92672">=</span> WordNetLemmatizer()
stop_words_en <span style="color:#f92672">=</span> stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_sentence</span>(text):
    <span style="color:#75715e"># lower</span>
    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()

    <span style="color:#75715e"># remove punctuation</span>
    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>,text)
    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>translate(str<span style="color:#f92672">.</span>maketrans(<span style="color:#e6db74">&#39;&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>,string<span style="color:#f92672">.</span>punctuation))

    <span style="color:#75715e"># tokenization</span>
    <span style="color:#75715e"># text.split(&#39; &#39;) # naive methods, e.g. New York will be splitted into [&#39;New&#39;, &#39;York&#39;]</span>
    tokens <span style="color:#f92672">=</span> word_tokenize(text) 

    <span style="color:#75715e"># lemmatize, [a, go, c, ...]</span>
    tokens <span style="color:#f92672">=</span> pos_tag(tokens) <span style="color:#75715e"># [(a, &#39;NN&#39;), (went, &#39;VB&#39;), (c, &#39;NN&#39;)]</span>
    tokens <span style="color:#f92672">=</span> [ lem<span style="color:#f92672">.</span>lemmatize(w, get_wordnet_pos(tag)) <span style="color:#66d9ef">for</span> w, tag <span style="color:#f92672">in</span> tokens ]

    <span style="color:#75715e"># remove stopping words</span>
    tokens <span style="color:#f92672">=</span> [ w <span style="color:#66d9ef">for</span> w <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> w <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> stop_words_en ]
    tokens <span style="color:#f92672">=</span> [ w <span style="color:#66d9ef">for</span> w <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> len(w) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> ]

    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(tokens)

</code></pre></div>



        
      </article>

      
      <aside class="article-aside">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#converting-text-to-lowercase">Converting text to lowercase</a></li>
    <li><a href="#removing-punctuation">Removing Punctuation</a></li>
    <li><a href="#tokenization">Tokenization</a></li>
    <li><a href="#stemming--lemmatization">Stemming &amp; Lemmatization</a>
      <ul>
        <li><a href="#stemming">Stemming</a></li>
        <li><a href="#lemmatization">Lemmatization</a></li>
      </ul>
    </li>
    <li><a href="#removing-stopping-words">Removing stopping words</a></li>
    <li><a href="#putting-it-together">Putting it together</a></li>
  </ul>
</nav>
      </aside>
      
    </div>

    

    
      

    
  </div>

    <footer>
  

<div class="social-icons">
  
    
    
      
      <a href="mailto:?to=xiaopan.wpp@outlook.com" name="Email">
        <em class="fas fa-envelope"></em>
      </a>
    
       &nbsp; &nbsp;
      <a href="https://github.com/ixiaopan" name="GitHub">
        <em class="fab fa-github"></em>
      </a>
    
       &nbsp; &nbsp;
      <a href="https://www.linkedin.com/in/ixiaopan" name="Linkedin">
        <em class="fab fa-linkedin"></em>
      </a>
    
       &nbsp; &nbsp;
      <a href="https://space.bilibili.com/22910840" name="Bilibili">
        <em class="fab fa-youtube"></em>
      </a>
    
  

  
</div>


  
  <div class="container">
    <p class="credits copyright">
      <a href="https://ixiaopan.github.io/blog/about">ixiaopan</a>
      &nbsp;&copy;
      2021
      
      &nbsp;&nbsp;
      <em class="fas fa-moon" id="dark-mode-toggle"></em>
    </p>

    <p class="credits theme-by">
      Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;
      Theme
      <a href="https://github.com/matsuyoshi30/harbor">Harbor</a>
    </p>
  </div>
</footer>

  </body>
</html>
